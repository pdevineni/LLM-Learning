{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG using Llamaindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[1624 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.7\" and (platform_machine != \"arm64\" or platform_system != \"Darwin\") and platform_machine != \"aarch64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.8\" and (platform_machine != \"arm64\" or platform_system != \"Darwin\") and platform_machine != \"aarch64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.7\" and platform_machine == \"aarch64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.8\" and platform_machine == \"aarch64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.8\" and platform_machine == \"arm64\" and platform_system == \"Darwin\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.9\" and platform_machine == \"arm64\" and platform_system == \"Darwin\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools>=38.6.0\n",
      "  \u001b[31m   \u001b[0m   Using cached setuptools-69.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting wheel\n",
      "  \u001b[31m   \u001b[0m   Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting Cython<3,>=0.29.21\n",
      "  \u001b[31m   \u001b[0m   Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting numpy==1.19.3\n",
      "  \u001b[31m   \u001b[0m   Using cached numpy-1.19.3.zip (7.3 MB)\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): still running...\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m Using cached setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "  \u001b[31m   \u001b[0m Building wheels for collected packages: numpy\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): still running...\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): still running...\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): still running...\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): finished with status 'error'\n",
      "  \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for numpy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[1582 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <string>:67: RuntimeWarning: NumPy 1.19.3 may not yet support Python 3.11.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Running from numpy source directory.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Cythonizing sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_bounded_integers.pxd.in has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_philox.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_bounded_integers.pyx.in has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_sfc64.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_mt19937.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/bit_generator.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Processing numpy/random/_bounded_integers.pyx\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2/numpy_0fe7886521ab42e9ad4b401cd17008a1/tools/cythonize.py:73: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   required_version = LooseVersion('0.29.21')\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2/numpy_0fe7886521ab42e9ad4b401cd17008a1/tools/cythonize.py:75: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   if LooseVersion(cython_version) < required_version:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/mtrand.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_generator.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_pcg64.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_common.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m blas_opt_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m blas_mkl_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries mkl_rt not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m blis_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries blis not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m openblas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries openblas not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_3_10_blas_threads_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Setting PTATLAS=ATLAS\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_3_10_blas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_blas_threads_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Setting PTATLAS=ATLAS\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_blas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m accelerate_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries accelerate not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Library accelerate was not found. Ignoring\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries veclib not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Library veclib was not found. Ignoring\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   FOUND:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     extra_compile_args = ['-msse3', '-I/System/Library/Frameworks/vecLib.framework/Headers']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     extra_link_args = ['-Wl,-framework', '-Wl,Accelerate']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   FOUND:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     extra_compile_args = ['-msse3', '-I/System/Library/Frameworks/vecLib.framework/Headers']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     extra_link_args = ['-Wl,-framework', '-Wl,Accelerate']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m non-existing path in 'numpy/distutils': 'site.cfg'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m lapack_opt_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m lapack_mkl_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries mkl_rt not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m openblas_lapack_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries openblas not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m openblas_clapack_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries openblas,lapack not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m flame_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries flame not found in ['/usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib', '/usr/local/lib', '/usr/lib']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_3_10_threads_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Setting PTATLAS=ATLAS\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_3_10_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_threads_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Setting PTATLAS=ATLAS\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <class 'numpy.distutils.system_info.atlas_info'>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   FOUND:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     extra_compile_args = ['-msse3', '-I/System/Library/Frameworks/vecLib.framework/Headers']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     extra_link_args = ['-Wl,-framework', '-Wl,Accelerate']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/setuptools/_distutils/dist.py:265: UserWarning: Unknown distribution option: 'define_macros'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   warnings.warn(msg)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running config_cc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running config_fc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m build_src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building py_modules sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building library \"npymath\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m None - nothing done with h_files = ['build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath/npy_math_internal.h']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building library \"npysort\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/common' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m None - nothing done with h_files = ['build/src.macosx-13.0-x86_64-3.11/numpy/core/src/common/npy_sort.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/common/npy_partition.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/common/npy_binsearch.h']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building library \"npyrandom\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._multiarray_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._multiarray_umath\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/common' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy.core - nothing done with h_files = ['build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/funcs.inc', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/simd.inc', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/loops.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/matmul.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/clip.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath/npy_math_internal.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/src/common/templ_common.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy/config.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy/_numpyconfig.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy/__multiarray_api.h', 'build/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy/__ufunc_api.h']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._umath_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._rational_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._struct_ufunc_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._operand_flag_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.fft._pocketfft_internal\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.linalg.lapack_lite\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.linalg._umath_linalg\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._mt19937\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._philox\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._pcg64\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._sfc64\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._common\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random.bit_generator\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._generator\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._bounded_integers\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random.mtrand\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building data_files sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m build_src: building npy-pkg config files\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/conftest.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/version.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/_globals.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/dual.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/_distributor_init.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ctypeslib.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matlib.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/_pytesttester.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying build/src.macosx-13.0-x86_64-3.11/numpy/__config__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/py3k.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/_inspect.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/tests/test_compat.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/umath.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/fromnumeric.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_dtype.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_add_newdocs.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_methods.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_internal.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_string_helpers.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/multiarray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_asarray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/records.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/setup_common.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/memmap.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/overrides.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/getlimits.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_dtype_ctypes.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/defchararray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/shape_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/machar.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/numeric.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/function_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/einsumfunc.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/umath_tests.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_ufunc_config.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_exceptions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/numerictypes.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_type_aliases.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/cversions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/arrayprint.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/code_generators/generate_numpy_api.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_add_newdocs.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_asarray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_dtype.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_dtype_ctypes.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_exceptions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_internal.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_methods.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_string_helpers.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_type_aliases.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_ufunc_config.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/arrayprint.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/cversions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/defchararray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/einsumfunc.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/fromnumeric.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/function_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/getlimits.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/machar.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/memmap.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/multiarray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/numeric.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/numerictypes.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/overrides.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/records.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/setup_common.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/shape_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/umath.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/umath_tests.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_numerictypes.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalar_methods.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalarmath.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_item_selection.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_machar.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_unicode.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_arrayprint.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalarbuffer.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_indexerrors.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_print.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_half.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_mem_overlap.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_shape_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_deprecations.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_errstate.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_records.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalarinherit.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_indexing.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_umath.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_numeric.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_function_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_datetime.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test__exceptions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_extint128.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_umath_complex.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/_locales.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_defchararray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_conversion_utils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalarprint.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_abc.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_ufunc.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_dtype.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_umath_accuracy.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_getlimits.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_einsum.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_api.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_longdouble.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_overrides.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalar_ctors.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_multiarray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_memmap.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_nditer.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_cpu_features.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_protocols.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_regression.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/unixccompiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/numpy_distribution.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/conv_template.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/cpuinfo.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/ccompiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/msvc9compiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/npy_pkg_config.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/misc_util.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/log.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/line_endings.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/lib2def.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/pathccompiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/system_info.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/core.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/exec_command.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/from_template.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/mingw32ccompiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/extension.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/msvccompiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/intelccompiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/_shell_utils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying build/src.macosx-13.0-x86_64-3.11/numpy/distutils/__config__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/config_compiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_ext.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/config.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/install_headers.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_py.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_src.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/sdist.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_scripts.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/bdist_rpm.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/install_clib.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_clib.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/autodist.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/egg_info.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/install.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/develop.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/install_data.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/gnu.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/compaq.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/intel.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/none.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/nag.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/pg.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/ibm.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/sun.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/nv.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/lahey.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/g95.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/mips.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/hpux.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/environment.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/pathf95.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/absoft.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/vast.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_system_info.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_mingw32ccompiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_from_template.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_fcompiler_intel.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_misc_util.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_fcompiler.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_shell_utils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_exec_command.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_npy_pkg_config.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_fcompiler_nagfor.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_fcompiler_gnu.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/misc.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/internals.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/creation.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/dispatch.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/constants.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/ufuncs.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/broadcasting.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/basics.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/subclassing.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/indexing.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/byteswapping.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/structured_arrays.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/glossary.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/cfuncs.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/common_rules.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/crackfortran.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/cb_rules.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/rules.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/f2py2e.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/func2subr.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/__version__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/diagnose.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/capi_maps.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/f90mod_rules.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/f2py_testing.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/use_rules.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/auxfuncs.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/__main__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_mixed.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_logical.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_assumed_shape.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_common.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_kind.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_array_from_pyobj.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_real.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/util.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_size.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_callback.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_string.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_quoted_character.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_parameter.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_semicolon_split.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_compile_function.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_block_docstring.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_integer.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_character.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_complex.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_crackfortran.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_regression.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/helper.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/_pocketfft.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/tests/test_pocketfft.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/tests/test_helper.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/_iotools.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/mixins.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/nanfunctions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/recfunctions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/histograms.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/scimath.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/_version.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/user_array.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/format.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/twodim_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/financial.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/index_tricks.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/npyio.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/shape_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/stride_tricks.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/utils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/arrayterator.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/function_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/arraysetops.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/arraypad.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/type_check.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/polynomial.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/_datasource.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/ufunclike.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_type_check.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_utils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_twodim_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_polynomial.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test__iotools.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_shape_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_ufunclike.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_index_tricks.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_arrayterator.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test__version.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_io.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_arraysetops.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_function_base.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_arraypad.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_mixins.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_packbits.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test__datasource.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_stride_tricks.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_financial.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_recfunctions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_nanfunctions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_format.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_histograms.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_regression.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/linalg.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/test_linalg.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/test_deprecations.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/test_build.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/test_regression.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/extras.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/testutils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/core.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/bench.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/timer_comparison.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/mrecords.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_old_ma.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_core.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_deprecations.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_subclassing.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_extras.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_mrecords.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_regression.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/defmatrix.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_matrix_linalg.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_defmatrix.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_interaction.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_numeric.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_masked_matrix.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_multiarray.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_regression.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/laguerre.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/_polybase.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/polyutils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/hermite_e.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/chebyshev.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/polynomial.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/legendre.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/hermite.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_chebyshev.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_hermite_e.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_polynomial.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_laguerre.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_legendre.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_printing.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_hermite.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_classes.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_polyutils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/_pickle.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_generator_mt19937.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_randomstate.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_direct.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_extending.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_smoke.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_randomstate_regression.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_seed_sequence.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_generator_mt19937_regressions.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_random.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_regression.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/setup.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/utils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/print_coercion_tables.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/nosetester.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/noseclasses.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/utils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/parameterized.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/decorators.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/tests/test_utils.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/tests/test_decorators.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/tests/test_doctesting.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_warnings.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_matlib.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_ctypeslib.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_numpy_version.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/__init__.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_reloading.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_public_api.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_scripts.py -> build/lib.macosx-13.0-x86_64-cpython-311/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_clib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler using new_build_clib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'npymath' library\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/core/src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/core/src/npymath\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -Inumpy/core/include -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/npymath/npy_math.cclang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath/npy_math_complex.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/npymath/halffloat.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath/ieee754.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m xcrun: adding 4 object files to build/temp.macosx-13.0-x86_64-cpython-311/libnpymath.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ranlib:@ build/temp.macosx-13.0-x86_64-cpython-311/libnpymath.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'npysort' library\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npysort\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npysort/mergesort.cclang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npysort/quicksort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npysort/heapsort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npysort/timsort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npysort/radixsort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npysort/selection.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npysort/binsearch.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:328:9: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp k;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/npysort/selection.c.src:326:14: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     else if (0 && kth == num - 1) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m              /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m 22 warnings generated.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m xcrun: adding 7 object files to build/temp.macosx-13.0-x86_64-cpython-311/libnpysort.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ranlib:@ build/temp.macosx-13.0-x86_64-cpython-311/libnpysort.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'npyrandom' library\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/random/src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/random/src/distributions\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-Inumpy/core/include -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/random/src/distributions/logfactorial.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/random/src/distributions/distributions.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/random/src/distributions/random_mvhg_marginals.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/random/src/distributions/random_mvhg_count.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/random/src/distributions/random_hypergeometric.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m xcrun: adding 5 object files to build/temp.macosx-13.0-x86_64-cpython-311/libnpyrandom.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ranlib:@ build/temp.macosx-13.0-x86_64-cpython-311/libnpyrandom.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler using new_build_ext\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'numpy.core._multiarray_tests' extension\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/core/src/common\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/mem_overlap.cclang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/_multiarray_tests.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang -bundle -undefined dynamic_lookup -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/_multiarray_tests.o build/temp.macosx-13.0-x86_64-cpython-311/numpy/core/src/common/mem_overlap.o -Lbuild/temp.macosx-13.0-x86_64-cpython-311 -lnpymath -o build/lib.macosx-13.0-x86_64-cpython-311/numpy/core/_multiarray_tests.cpython-311-darwin.so\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'numpy.core._multiarray_umath' extension\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/core/src/multiarray\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/numpy/core/src/umath\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src/common\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders/db\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2/numpy_0fe7886521ab42e9ad4b401cd17008a1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2/numpy_0fe7886521ab42e9ad4b401cd17008a1/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2/numpy_0fe7886521ab42e9ad4b401cd17008a1/numpy/_build_utils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.macosx-13.0-x86_64-cpython-311/private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2/numpy_0fe7886521ab42e9ad4b401cd17008a1/numpy/_build_utils/src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m extra options: '-msse3 -I/System/Library/Frameworks/vecLib.framework/Headers'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/alloc.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/arrayfunction_override.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/datetime_strings.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/convert.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/arrayobject.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/buffer.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/convert_datatype.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/datetime_busday.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/calculation.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/conversion_utils.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/datetime_busdaycal.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/arraytypes.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/descriptor.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/compiled_base.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/ctors.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/dragon4.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/common.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/datetime.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/dtype_transfer.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/item_selection.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/multiarraymodule.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/einsum.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/einsum.c.src:2158:32: warning: unknown warning group '-Wmaybe-uninitialized', ignored [-Wunknown-warning-option]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m #pragma GCC diagnostic ignored \"-Wmaybe-uninitialized\"\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                                ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/iterators.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/lowlevel_strided_loops.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/nditer_templ.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/nditer_api.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/nditer_constr.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/nditer_pywrap.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m 1 warning generated.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/flagsobject.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/array_assign_scalar.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/array_assign_array.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/getset.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/number.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/scalartypes.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/hashdescr.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:1880:9: warning: variable 'i' set but not used [-Wunused-but-set-variable]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     int i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:1880:9: warning: variable 'i' set but not used [-Wunused-but-set-variable]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     int i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:1880:9: warning: variable 'i' set but not used [-Wunused-but-set-variable]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     int i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:1880:9: warning: variable 'i' set but not used [-Wunused-but-set-variable]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     int i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/vdot.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2967:65: error: too few arguments to function call, expected 2, have 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, Float));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m            ~~~~~~~~~~~~~~                                       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/pyhash.h:10:23: note: '_Py_HashDouble' declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2976:48: error: too few arguments to function call, expected 2, have 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m             PyArrayScalar_VAL(obj, CFloat).real);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                                                ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/pyhash.h:10:23: note: '_Py_HashDouble' declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2982:48: error: too few arguments to function call, expected 2, have 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m             PyArrayScalar_VAL(obj, CFloat).imag);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                                                ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/pyhash.h:10:23: note: '_Py_HashDouble' declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2967:70: error: too few arguments to function call, expected 2, have 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, LongDouble));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m            ~~~~~~~~~~~~~~                                            ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/pyhash.h:10:23: note: '_Py_HashDouble' declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2976:53: error: too few arguments to function call, expected 2, have 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m             PyArrayScalar_VAL(obj, CLongDouble).real);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                                                     ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/pyhash.h:10:23: note: '_Py_HashDouble' declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2982:53: error: too few arguments to function call, expected 2, have 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m             PyArrayScalar_VAL(obj, CLongDouble).imag);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                                                     ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/pyhash.h:10:23: note: '_Py_HashDouble' declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2997:75: error: too few arguments to function call, expected 2, have 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m            ~~~~~~~~~~~~~~                                                 ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/pyhash.h:10:23: note: '_Py_HashDouble' declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m 4 warnings and 7 errors generated.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/clip.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/refcount.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/umath/umathmodule.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/umath/reduction.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/sequence.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/shape.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/loops.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/umath/ufunc_object.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/scalarapi.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In file included from numpy/core/src/umath/loops.c.src:50:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if ((IS_OUTPUT_BLOCKABLE_UNARY((npy_uint)(8/1), 64)) &&\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m          ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if ((IS_OUTPUT_BLOCKABLE_UNARY((npy_uint)(8/2), 64)) &&\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m          ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if ((IS_OUTPUT_BLOCKABLE_UNARY((npy_uint)(8/1), 64)) &&\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m          ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if ((IS_OUTPUT_BLOCKABLE_UNARY((npy_uint)(16/1), 64)) &&\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m          ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if ((IS_OUTPUT_BLOCKABLE_UNARY((npy_uint)(16/2), 64)) &&\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m          ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if ((IS_OUTPUT_BLOCKABLE_UNARY((npy_uint)(16/1), 64)) &&\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m          ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:247:10: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:117:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ((abs(steps[0]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:117:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ((abs(steps[0]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:118:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[1]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:118:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[1]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:119:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[2]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:119:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[2]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:117:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ((abs(steps[0]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:117:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ((abs(steps[0]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:118:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[1]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:118:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[1]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:119:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[2]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:119:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[2]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:117:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ((abs(steps[0]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:117:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ((abs(steps[0]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:118:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[1]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:118:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[1]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:119:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[2]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:119:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[2]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:117:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ((abs(steps[0]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:117:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ((abs(steps[0]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:118:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[1]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:118:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[1]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:119:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[2]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:287:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:119:7: note: expanded from macro 'IS_BINARY_SMALL_STEPS_AND_NOMEMOVERLAP'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m      (abs(steps[2]) < MAX_STEP_SIZE)  && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:354:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:354:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:354:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:354:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:375:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 32)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:375:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:328:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:354:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:354:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:354:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:354:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:375:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_float), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:375:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:396:9: warning: absolute value function 'abs' given an argument of type 'const npy_intp' (aka 'const long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_OUTPUT_BLOCKABLE_UNARY(sizeof(npy_double), 64)) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:396:9: note: use function 'labs' instead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/simd.inc.src:129:29: note: expanded from macro 'IS_OUTPUT_BLOCKABLE_UNARY'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     (steps[1] == (esize) && abs(steps[0]) < MAX_STEP_SIZE && \\\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalarapi.c:759:38: warning: 'ob_shash' is deprecated [-Wdeprecated-declarations]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m             ((PyStringObject *)obj)->ob_shash = -1;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                                      ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/cpython/bytesobject.h:7:5: note: 'ob_shash' has been explicitly marked deprecated here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Py_DEPRECATED(3.11) Py_hash_t ob_shash;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11/pyport.h:336:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                                                      ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m 1 warning generated.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/umath/override.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/npymath/npy_math.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath/ieee754.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath/npy_math_complex.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/npymath/halffloat.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/umath/extobj.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/array_assign.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/scalarmath.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/mem_overlap.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/loops.c.src:2611:22: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp n = dimensions[0];\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/loops.c.src:2610:29: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_REDUCE && 0) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/loops.c.src:2611:22: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp n = dimensions[0];\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/loops.c.src:2610:29: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_REDUCE && 0) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/loops.c.src:2611:22: warning: code will never be executed [-Wunreachable-code]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m         npy_intp n = dimensions[0];\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/umath/loops.c.src:2610:29: note: silence by adding parentheses to mark code as explicitly dead\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     if (IS_BINARY_REDUCE && 0) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                             /* DISABLES CODE */ ( )\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/npy_longdouble.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/ucsnarrow.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/ufunc_override.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/numpyos.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/common/npy_cpu_features.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/cblasfuncs.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/common/python_xerbla.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: /private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2/numpy_0fe7886521ab42e9ad4b401cd17008a1/numpy/_build_utils/src/apple_sgemv_fix.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In file included from /private/var/folders/db/tfb_bhgd25z6blhh32r8w5rm0000gn/T/pip-install-8jskgwz2/numpy_0fe7886521ab42e9ad4b401cd17008a1/numpy/_build_utils/src/apple_sgemv_fix.c:26:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In file included from numpy/core/include/numpy/arrayobject.h:4:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In file included from numpy/core/include/numpy/ndarrayobject.h:21:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m build/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy/__multiarray_api.h:1463:1: warning: unused function '_import_array' [-Wunused-function]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m _import_array(void)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m 1 warning generated.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/umath/ufunc_type_resolution.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/mapping.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: numpy/core/src/multiarray/methods.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m 60 warnings generated.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m clang: build/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath/matmul.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m error: Command \"clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/umath -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/common -Ibuild/src.macosx-13.0-x86_64-3.11/numpy/core/src/npymath -c build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/scalartypes.c -o build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/scalartypes.o -MMD -MF build/temp.macosx-13.0-x86_64-cpython-311/build/src.macosx-13.0-x86_64-3.11/numpy/core/src/multiarray/scalartypes.o.d -msse3 -I/System/Library/Frameworks/vecLib.framework/Headers\" failed with exit status 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m \u001b[0mFailed to build numpy\n",
      "  \u001b[31m   \u001b[0m \u001b[31mERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m \u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "### Setup environment \n",
    "\n",
    "!python3 -m venv rag-pipeline -- quiet\n",
    "!source rag/bin/activate --quiet\n",
    "\n",
    "##### Install dependencies\n",
    "\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "docs0 = loader.load_data(file_path=Path(\"data/State of AI Report 2023.pdf\"), metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " docs is a <class 'list'>, of length 163, where each element is a <class 'llama_index.core.schema.Document'> object\n"
     ]
    }
   ],
   "source": [
    "print(f\" docs is a {type(docs0)}, of length {len(docs0)}, where each element is a {type(docs0[0])} object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_', 'embedding', 'metadata', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'relationships', 'text', 'start_char_idx', 'end_char_idx', 'text_template', 'metadata_template', 'metadata_seperator']\n",
      "    In Oct 2022, Shutterstock - a leading stock multimedia provider - announced it will work with OpenAI to bring \n",
      "DALL·E-powered content onto the platform. Then in July 2023, the two companies signed a 6-year content \n",
      "licensing agreement that would give OpenAI access to Shutterstock's image, video and music libraries and \n",
      "associated metadata for model training. Furthermore, Shutterstock will offer its customers indemniﬁcation for AI \n",
      "image creation. The company also entered into a content license with Meta for GenAI. This pro-GenAI stance is in \n",
      "stark contrast to Shutterstock’s competitor, Getty Images, which is profoundly against GenAI as evidenced by its \n",
      "ongoing lawsuit against Stability AI for copyright infringement ﬁled in Feb 2023. \n",
      "stateof.ai 2023\n",
      "#stateofai | 95\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "2022 Prediction: A major user generated content site negotiates a commercial \n",
      "settlement with a start-up producing AI models (e.g. OpenAI) for training on their corpus\n",
      "vs.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(id_='53bd5f4e-ceb7-4836-946b-f89c316f5175', embedding=None, metadata={'total_pages': 163, 'file_path': 'data/State of AI Report 2023.pdf', 'source': '95'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"    In Oct 2022, Shutterstock - a leading stock multimedia provider - announced it will work with OpenAI to bring \\nDALL·E-powered content onto the platform. Then in July 2023, the two companies signed a 6-year content \\nlicensing agreement that would give OpenAI access to Shutterstock's image, video and music libraries and \\nassociated metadata for model training. Furthermore, Shutterstock will offer its customers indemniﬁcation for AI \\nimage creation. The company also entered into a content license with Meta for GenAI. This pro-GenAI stance is in \\nstark contrast to Shutterstock’s competitor, Getty Images, which is profoundly against GenAI as evidenced by its \\nongoing lawsuit against Stability AI for copyright infringement ﬁled in Feb 2023. \\nstateof.ai 2023\\n#stateofai | 95\\n Introduction | Research | Industry | Politics | Safety | Predictions\\n2022 Prediction: A major user generated content site negotiates a commercial \\nsettlement with a start-up producing AI models (e.g. OpenAI) for training on their corpus\\nvs.\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ([k for k, v in docs0[94]])\n",
    "\n",
    "print (docs0[94].get_content())\n",
    "\n",
    "[v for k,v in docs0[94] if k=='metadata']\n",
    "\n",
    "docs0[94]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text and add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_slide_text(text:str) -> str: \n",
    "    \"\"\"\n",
    "    Cleans the provided slide by removing specific patterns and extra whitespace. \n",
    "    \n",
    "    Parameters:\n",
    "\n",
    "    Returns: \n",
    "    \"\"\"\n",
    "    # Remove the footer text\n",
    "    text = text.replace(\"stateof.ai 2023\", \"\")\n",
    "\n",
    "    # Remove the header text\n",
    "    text = text.replace(\"Introduction  | Research  | Industry  | Politics  | Safety  | Predictions\", \"\")\n",
    "\n",
    "    # Remove the pattern \"#stateofai | n\"\n",
    "    text = re.sub(r\"#stateofai(\\s*\\|\\s*\\d+)?\", \"\", text)\n",
    "\n",
    "    # Replace multiple consecutive spaces with a single space\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "\n",
    "    # Remove any leading or trailing whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_section(document):\n",
    "    \"\"\"\n",
    "    Assigns a section to the document based on its page number.\n",
    "\n",
    "    The function updates the 'metadata' attribute of the document with a key 'section'\n",
    "    that has a value corresponding to the section the page number falls into.\n",
    "\n",
    "    Sections:\n",
    "    - Page 1 through 10: Introduction\n",
    "    - Page 11 through 68: Research\n",
    "    - Page 69 through 120: Politics\n",
    "    - Page 121 through 137: Safety\n",
    "    - Pages 138 and beyond: Predictions\n",
    "\n",
    "    Args:\n",
    "    - document (Document): The Document object to be updated.\n",
    "\n",
    "    Returns:\n",
    "    None. The function updates the Document object in-place.\n",
    "    \"\"\"\n",
    "\n",
    "    page_number = int(document.metadata['source'])\n",
    "\n",
    "    if 1 <= page_number <= 10:\n",
    "        document.metadata['section'] = 'Introduction'\n",
    "    elif 11 <= page_number <= 68:\n",
    "        document.metadata['section'] = 'Research'\n",
    "    elif 69 <= page_number <= 120:\n",
    "        document.metadata['section'] = 'Politics'\n",
    "    elif 121 <= page_number <= 137:\n",
    "        document.metadata['section'] = 'Safety'\n",
    "    else:\n",
    "        document.metadata['section'] = 'Predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State of AI Report\n",
      "October 12, 2023\n",
      "Nathan Benaich\n",
      "Air Street Capital\n",
      "\n",
      "stateof.ai\n",
      "About the authors\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "\n",
      "Nathan is the General Partner of Air Street Capital, a \n",
      "venture capital ﬁrm investing in AI-ﬁrst technology \n",
      "and life science companies. He founded RAAIS and \n",
      "London.AI (AI community for industry and research), \n",
      "the RAAIS Foundation (funding open-source AI \n",
      "projects), and Spinout.fyi (improving university spinout \n",
      "creation). He studied biology at Williams College and \n",
      "earned a PhD from Cambridge in cancer research. \n",
      "Nathan Benaich\n",
      "State of AI Report 2023 team\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "Othmane Sebbouh\n",
      "Venture Fellow\n",
      "Othmane is a Venture Fellow at Air \n",
      "Street Capital and ML PhD student at \n",
      "ENS Paris, CREST-ENSAE and CNRS. \n",
      "He holds an MsC in management \n",
      "from ESSEC Business School and a \n",
      "Master in Applied Mathematics from \n",
      "ENSAE and Ecole Polytechnique.\n",
      "Alex Chalmers\n",
      "Platform Lead\n",
      "Alex is Platform Lead at Air Street \n",
      "Capital. \n",
      "Alex \n",
      "was \n",
      "previously \n",
      "Associate \n",
      "Director \n",
      "at \n",
      "Milltown \n",
      "Partners where he advised leading \n",
      "technology companies including AI \n",
      "labs. \n",
      "Corina Gurau\n",
      "Venture Fellow\n",
      "Corina is a Venture Fellow at Air \n",
      "Street Capital. Corina was previously \n",
      "an Applied Scientist at autonomous \n",
      "driving company, Wayve. She holds a \n",
      "PhD in AI from the University of \n",
      "Oxford.\n",
      "Artiﬁcial intelligence (AI) is a multidisciplinary ﬁeld of science and engineering whose goal is to create intelligent machines.\n",
      "We believe that AI will be a force multiplier on technological progress in our increasingly digital, data-driven world. This is \n",
      "because everything around us today, ranging from culture to consumer products, is a product of intelligence. \n",
      "The State of AI Report is now in its sixth year. Consider this report as a compilation of the most interesting things we’ve seen \n",
      "with a goal of triggering an informed conversation about the state of AI and its implication for the future. \n",
      "We consider the following key dimensions in our report:\n",
      "-\n",
      "Research: Technology breakthroughs and their capabilities.\n",
      "-\n",
      "Industry: Areas of commercial application for AI and its business impact.\n",
      "-\n",
      "Politics: Regulation of AI, its economic implications and the evolving geopolitics of AI.\n",
      "-\n",
      "Safety: Identifying and mitigating catastrophic risks that highly-capable future AI systems could pose to us.\n",
      "-\n",
      "Predictions: What we believe will happen in the next 12 months and a 2022 performance review to keep us honest.\n",
      "Produced by Nathan Benaich and Air Street Capital team\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Artiﬁcial intelligence (AI): a broad discipline with the goal of creating intelligent machines, as opposed to the natural intelligence that is \n",
      "demonstrated by humans and animals.\n",
      "Artiﬁcial general intelligence (AGI): a term used to describe future machines that could match and then exceed the full range of human cognitive \n",
      "ability across all economically valuable tasks.\n",
      "AI Agent: an AI-powered system that can take actions in an environment. For example, an LLM that has access to a suite of tools and has to decide \n",
      "which one to use in order to accomplish a task that it has been prompted to do.\n",
      "AI Safety: a ﬁeld that studies and attempts to mitigate the risks (minor to catastrophic) which future AI could pose to humanity.\n",
      "Computer vision (CV): the ability of a program to analyse and understand images and video. \n",
      "Deep learning (DL): an approach to AI inspired by how neurons in the brain recognise complex patterns in data. The “deep” refers to the many layers \n",
      "of neurons in today’s models that help to learn rich representations of data to achieve better performance gains.\n",
      "Diffusion: An algorithm that iteratively denoises an artiﬁcially corrupted signal in order to generate new, high-quality outputs. In recent years it has \n",
      "been at the forefront of image generation.\n",
      "Generative AI: A family of AI systems that are capable of generating new content (e.g. text, images, audio, or 3D assets) based on 'prompts'.\n",
      "Graphics Processing Unit (GPU): a semiconductor processing unit that enables a large number calculations to be computed in parallel. Historically \n",
      "this was required for rendering computer graphics. Since 2012 GPUs have adapted for training DL models, which also require a large number of \n",
      "parallel calculations.\n",
      "Deﬁnitions\n",
      "(Large) Language model (LM, LLM): a model trained on vast amounts of (often) textual data to predict the next word in a self-supervised manner. \n",
      "The term “LLM” is used to designate multi-billion parameter LMs, but this is a moving deﬁnition.\n",
      "Machine learning (ML): a subset of AI that often uses statistical techniques to give machines the ability to \"learn\" from data without being explicitly \n",
      "given the instructions for how to do so. This process is known as “training” a “model” using a learning “algorithm” that \n",
      "progressively improves model performance on a speciﬁc task.\n",
      "Model: a ML algorithm trained on data and used to make predictions.\n",
      "Natural language processing (NLP): the ability of a program to understand human language as it is spoken and written.\n",
      "Prompt: a user input often written in natural language that is used to instruct an LLM to generate something or take action.\n",
      "Reinforcement learning (RL): an area of ML in which software agents learn goal-oriented behavior by trial and error in an environment that \n",
      "provides rewards or penalties in response to their actions (called a “policy”) towards achieving that goal.\n",
      "Self-supervised learning (SSL): a form of unsupervised learning, where manually labeled data is not needed. Raw data is instead modiﬁed in an \n",
      "automated way to create artiﬁcial labels to learn from. An example of SSL is learning to complete text by masking random words in a sentence and \n",
      "trying to predict the missing ones.\n",
      "Transformer: a model architecture at the core of most state of the art (SOTA) ML research. It is composed of multiple “attention” layers which learn \n",
      "which parts of the input data are the most important for a given task. Transformers started in NLP (speciﬁcally machine translation) and \n",
      "subsequently were expanded into computer vision, audio, and other modalities.\n",
      "Deﬁnitions\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Model type legend\n",
      "In the rest of the slides, icons in the top right corner indicate input and output modalities for the model. \n",
      "Input/Output types:\n",
      "📝: Text\n",
      "🖼: Image\n",
      "</> : Code \n",
      "🛠 : Software tool use (text, code generation & execution) \n",
      "🎥 : Video \n",
      "🎵: Music \n",
      "📦: 3D\n",
      "🤖: Robot state\n",
      "Deﬁnitions\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Model types:\n",
      "📝 → 📝 : LLMs \n",
      "📝+ 🖼 → 📝 : Multimodal LLMs\n",
      "📝+ 🖼+ 🤖 → 📝 : Multimodal LLMs for Robotics\n",
      "📝 → </> : Text to Code \n",
      "📝 → 🛠 : Text to Software tool use \n",
      "📝 → 🖼 : Text to Image\n",
      "📝 → 🎥 : Text to Video \n",
      "📝 → 🎵 : Text to Music \n",
      "🖼 → 📦 : Image to 3D\n",
      "📝 → 📦 : Text to 3D\n",
      "Research\n",
      "-\n",
      "GPT-4 lands and demonstrates a capabilities chasm between proprietary and next-best open source alternatives, while also validating the power of \n",
      "reinforcement learning from human feedback. \n",
      "-\n",
      "Efforts grow to clone or beat proprietary model performance with smaller models, better datasets, longer context…powered by LLaMa-1/2.\n",
      "-\n",
      "It’s unclear how long human-generated data can sustain AI scaling trends (some estimate that data will be exhausted by LLMs by 2025) and what the effects \n",
      "of adding synthetic data are. Videos and data locked up in enterprises are likely up next. \n",
      "-\n",
      "LLMs and diffusion models continue to offer gifts to the life science community by producing new breakthroughs for molecular biology and drug discovery. \n",
      "-\n",
      "Multimodality becomes the new frontier and excitement around agents of all ﬂavors grows substantially. \n",
      "Industry\n",
      "-\n",
      "NVIDIA rips into the $1T market cap club with voracious demand for its GPUs from nation states, startups, big tech and researchers alike.\n",
      "-\n",
      "Export controls rate limit advanced chip sales to China, but major chip vendors create export control-proof alternatives. \n",
      "-\n",
      "Led by ChatGPT, GenAI apps have a breakout year across image, video, coding, voice or CoPilots for everyone, driving $18B of VC and corporate investments. \n",
      "Politics\n",
      "-\n",
      "The world has divided into clear regulatory camps, but progress on global governance remains slower. The largest AI labs are stepping in to ﬁll the vacuum.\n",
      "-\n",
      "The chip wars continue unabated, with the US mobilising its allies, and the Chinese response remaining patchy.\n",
      "-\n",
      "AI is forecast to affect a series of sensitive areas, including elections and employment, but we’re yet to see a signiﬁcant effect.\n",
      "Safety\n",
      "-\n",
      "The existential risk debate has reached the mainstream for the ﬁrst time and intensiﬁed signiﬁcantly.\n",
      "-\n",
      "Many high-performing models are easy to ‘jailbreak’. To remedy RLHF challenges, researchers are exploring alternatives, e.g. self-alignment and pretraining \n",
      "with human preferences.\n",
      "-\n",
      "As capabilities advance, it’s becoming increasingly hard to evaluate SOTA models consistently. Vibes won’t sufﬁce.\n",
      "Executive Summary\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Scorecard: Reviewing our predictions from 2022\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Our 2022 Prediction\n",
      "Evidence\n",
      "A 10B parameter multimodal RL model is trained by DeepMind 10x larger than Gato.\n",
      "NO\n",
      "So far there has been no publicly disclosed research along these lines. \n",
      "NVIDIA announces a strategic relationship with an AGI focused organisation.\n",
      "~\n",
      "Instead of one relationship, NVIDIA has ramped its investment activities across many AGI focused \n",
      "organisations including Cohere, Inﬂection AI, and Adept.\n",
      "A SOTA LM is trained on 10x more data points than Chinchilla, proving data-set scaling \n",
      "vs. parameter scaling\n",
      "YES\n",
      "We don’t know for sure, but GPT-4 was reportedly trained on 13T tokens vs. Chinchilla’s 1.4T. Meta’s \n",
      "Llama-2 was trained on 2T tokens. \n",
      "Generative audio tools emerge that attract over 100,000 developers by September 2023.\n",
      "YES\n",
      "Both ElevenLabs and Resemble.ai claim over 1 million users each since launch.\n",
      "GAFAM invests >$1B into an AGI or open source AI company (e.g. OpenAI).\n",
      "YES\n",
      "Microsoft invested a further $10B into OpenAI in Jan. 2023.\n",
      "Reality bites for semiconductor startups in the face of NVIDIA’s dominance and a high \n",
      "proﬁle start-up is shut down or acquired for <50% of its most recent valuation.\n",
      "NO\n",
      "There have been markdowns, but no major shutdowns or depressed acquisitions.\n",
      "A proposal to regulate AGI Labs like Biosafety Labs (BSL) gets backing from an elected \n",
      "UK, US or EU politician.\n",
      "NO\n",
      "Calls for regulation have signiﬁcantly heightened, but no backing for BSL yet.\n",
      ">$100M is invested in dedicated AI Alignment organisations in the next year as we \n",
      "become aware of the risk we are facing by letting AI capabilities run ahead of safety.\n",
      "YES\n",
      "Anthropic, an AI research and safety company, raised up to $4B in Sept 2023. \n",
      "A major user generated content site (e.g. Reddit) negotiates a commercial settlement \n",
      "with a start-up producing AI models (e.g. OpenAI) for training on their corpus of user \n",
      "generated content.\n",
      "YES\n",
      "OpenAI has secured a 6-year license for access to additional Shutterstock training data (image, video \n",
      "and music libraries and associated metadata).\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Section 1: Research\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "GPT-4 is OpenAI’s latest Large Language Model. In contrast with text-only GPT-3 and follow-ups, GPT-4 is \n",
      "multimodal: it was trained on both text and images; it can among other capabilities generate text based on \n",
      "images. At 8,192 tokens when it was released, it had already exceeded the previous-best GPT-3.5 in possible \n",
      "input size. It is, of course, trained using RLHF. Equipped with these advances, GPT-4 is, as of the release of this \n",
      "report, the uncontested most generally capable AI model.\n",
      "\n",
      "\n",
      "GPT-4 is out and it crushes every other LLM, and many humans\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● OpenAI did a comprehensive evaluation of GPT-4 not only on classical NLP \n",
      "benchmarks, but also on exams designed to evaluate humans (e.g. Bar exam, \n",
      "GRE, Leetcode).\n",
      "● GPT-4 is the best model across the board. It solves some tasks that GPT-3.5 \n",
      "was unable to, like the Uniform Bar Exam where GPT-4 scores 90% \n",
      "compared to 10% for GPT-3.5. On most tasks, the added vision component \n",
      "had only a minor impact, but it helped tremendously on others.\n",
      "● OpenAI reports that although GPT-4 still suffers from hallucinations, it is \n",
      "factually correct 40% more often than the previous-best ChatGPT model on \n",
      "an adversarial truthfulness dataset (generated to fool AI models).\n",
      "📝 → 📝\n",
      "In last year’s Safety section (Slide 100), we highlighted how Reinforcement Learning from Human Feedback \n",
      "(RLHF) – used in InstructGPT – helped make OpenAI’s models safer and more helpful for users. Despite a few \n",
      "hiccups, ChatGPT’s success proved the technique’s viability at a massive scale.\n",
      "\n",
      "● “RLHF involves humans ranking language model outputs sampled for a given \n",
      "input, using these rankings to learn a reward model of human preferences, and \n",
      "then using this as a reward signal to ﬁnetune the language model with using \n",
      "RL.” In its modern form, it dates back to 2017, when OpenAI and DeepMind \n",
      "researchers applied it to incorporate human feedback in training agents \n",
      "on Atari games and to other RL applications.\n",
      "● RLHF is now central to the success of state of the art LLMs, especially \n",
      "those designed for chat applications. These include Anthropic’s Claude, \n",
      "Google’s Bard, Meta’s LLaMa-2-chat, and, of course, OpenAI’s ChatGPT.\n",
      "● RLHF requires hiring humans to evaluate and rank model outputs, and \n",
      "then models their preferences. This makes this technique hard, expensive, \n",
      "and biased¹. This motivated researchers to look for alternatives.\n",
      "\n",
      "Fueled by ChatGPT’s success, RLHF becomes MVP\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Typical steps of RLHF, which follow an initial step of supervised \n",
      "ﬁne-tuning of a pre-trained language model, e.g. GPT-3.\n",
      "¹ We will cover other issues of RLHF in the Safety section.\n",
      "📝 → 📝\n",
      "● By using model size as a proxy for quality, the \n",
      "authors argue that more attention should be paid \n",
      "to better pre-training rather than ﬁne-tuning on \n",
      "more imitation data.\n",
      "● In the near future, RLHF seems here to stay. After \n",
      "careful ablation studies, Meta researchers \n",
      "concluded in their LLaMa-2 paper: “We posit that \n",
      "the superior writing abilities of LLMs, as manifested \n",
      "in surpassing human annotators in certain tasks, are \n",
      "fundamentally driven by RLHF”.\n",
      "● The researchers examine a range of pretrained LLMs of different sizes and pre-trained on a varying amount of \n",
      "data. They show that at a ﬁxed model size, using more imitation data actually hurts the quality of the output. In \n",
      "turn, larger models beneﬁt from using imitation data.\n",
      " Berkeley researchers show that ﬁne-tuning small LLMs on the outputs of larger, more capable LLMs results in \n",
      "models which are stylistically impressive but which often produce inaccurate text.\n",
      "\n",
      "\n",
      "The false promise of imitating proprietary LLMs, or how RLHF is still king\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "In the wake of ChatGPT, many labs set out to answer the question: Can we create models as capable and safe as \n",
      "OpenAI’s LLMs, but that drastically reduce human supervision?\n",
      "\n",
      "● Anthropic proposed RL from AI feedback, which we cover in the safety section.\n",
      "● Other approaches entirely do a way with reinforcement learning. In Less is More \n",
      "for Alignment (LIMA), Meta argues for using a few (1,000 in their paper) very \n",
      "carefully curated prompts and responses. According to human evaluations of \n",
      "model outputs, LIMA is competitive with GPT-4 in 43% of cases.\n",
      "● In LLMs can self-improve, Google researchers showed that LLMs can improve by \n",
      "training on their own outputs. In a similar vein, Self-Instruct is a framework in \n",
      "which a model generates its own instructions, input and output samples, and \n",
      "curates them to ﬁnetune its parameters. Yet another work in this direction is \n",
      "Meta’s Self-Alignment with Instruction Backtranslation.\n",
      "● Stanford researchers used this last approach to generate instructions and \n",
      "outputs using GPT-3.5 and ﬁne-tune Meta’s LLaMa-7B.\n",
      "\n",
      "Even so, researchers rush to ﬁnd scalable alternatives to RLHF\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "OpenAI published a technical report on GPT-4 where it didn’t disclose any useful information for AI researchers, \n",
      "signalling the deﬁnitive industrialization of AI research. Google’s PaLM-2 technical report suffered the same fate, \n",
      "while (OpenAI spinoff) Anthropic didn’t bother releasing a technical report for its Claude models.\n",
      "\n",
      "● “Given both the competitive landscape and the safety implications of \n",
      "large-scale models like GPT-4, this report contains no further details about \n",
      "the architecture (including model size), hardware, training compute, \n",
      "dataset construction, training method, or similar”, OpenAI writes in the \n",
      "GPT-4 technical report published on arXiv.\n",
      "● When Google released PaLM 2, its most capable LLM, the company \n",
      "wrote in the technical report: “Further details of model size and \n",
      "architecture are withheld from external publication.”\n",
      "● As the economic stakes and the safety concerns are getting higher \n",
      "(you can choose what to believe), traditionally open companies have \n",
      "embraced a culture of opacity about their most cutting edge research.\n",
      "\n",
      "The GPT-4 technical report puts the nail in the cofﬁn of SOTA LLM research…\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "In February ’23, Meta released a series of models called LLaMa. At their release, they stood out as being the most \n",
      "capable models trained exclusively on publicly available datasets. Meta initially granted access to the LLaMa \n",
      "model weights on demand only to researchers, but the weights were quickly leaked and published online. \n",
      "\n",
      "● The LLaMa-1 models use regular transformers, with slight changes to the \n",
      "architecture. The authors also made a few changes to the optimizer and to the \n",
      "implementation of attention. As a result, “when training a 65B-parameter model, \n",
      "[their] code processes around 380 tokens/sec/GPU on 2048 A100 GPU with 80GB of \n",
      "RAM. This means that training over [their] dataset containing 1.4T tokens takes \n",
      "approximately 21 days.”\n",
      "● The LLaMa-1 models outperform GPT-3 (the original one, not the InstructGPT \n",
      "variants) and are competitive with DeepMind’s Chinchilla and Google’s PaLM.\n",
      "● LLaMa-1 didn’t allow commercial use, prompting heavy criticism around the \n",
      "term “open-source” that Meta used to describe the model release. But a second \n",
      "LLaMa iteration appeased most of the open source community.\n",
      "\n",
      "…unless LLaMas reverse the trend\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "After Meta released LLaMa-1, other institutions joined the movement to release the weights of relatively large \n",
      "language models. A few of them stand out, like MosaicML’s MPT-30B, TII UAE’s Falcon-40B, Together’s \n",
      "RedPajama, or Eleuther’s Pythia. Meanwhile another dynamic was taking place, where the open-source \n",
      "community ﬁne-tuned the smallest versions of LLaMa on specialized datasets and applied them to dozens of \n",
      "downstream applications. Mistral AI’s 7B model also recently emerged as the strongest small model.\n",
      "\n",
      "● Notably, RedPajama aimed to exactly replicate LLaMa-1 to make it fully \n",
      "open-source. Falcon 40B came from a new entrant in the LLM sweepstakes, TII \n",
      "UAE, and was quickly made open-source. Falcon-180B was later released, but \n",
      "was notably trained on very little code, and not tested on coding.\n",
      "● Helped with parameter-efﬁcient ﬁne-tuning methods like LoRa (Low-rank \n",
      "adaptation of LLMs – initially by Microsoft), LM practitioners started \n",
      "ﬁne-tuning these pre-trained LLMs for speciﬁc applications like (of course) \n",
      "chat. One example is LMSys’s Vicuna which is LLaMa ﬁne-tuned on \n",
      "user-shared conversations with ChatGPT.\n",
      "\n",
      "LLaMa sets off a race of open(ish) competitive Large Language Models\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "In July ’23, the LLaMa-2 series of models was released, giving (almost) everyone the right for commercial use. \n",
      "The base LLaMa-2 model is almost identical to LLaMa-1 but further ﬁne-tuned using instruction tuning and \n",
      "RLHF and optimized for dialogue applications. In September 2023, Llama-2 as had almost 32M downloads.\n",
      "\n",
      "● The pre-training corpus for LLaMa-2 has 2 trillion tokens (40% increase).\n",
      "● For supervised ﬁne-tuning, the researchers tried publicly available data, \n",
      "but what was most helpful was using a few (24,540) high-quality \n",
      "vendor-based annotations. For RLHF, they use binary comparison and \n",
      "split the RLHF process into prompts and answers designed to be helpful \n",
      "to the user and others designed to be safe.\n",
      "● LLaMa-2 70B is competitive with ChatGPT on most tasks except for \n",
      "coding, where it signiﬁcantly lags behind it. But CodeLLaMa, a ﬁne-tuned \n",
      "version for code beats all non-GPT4 models (more on this later). \n",
      "● Per Meta terms, anyone (with enough hardware to run the models) can \n",
      "use the LLaMa-2 models, as long as their commercial application didn’t \n",
      "have more than 700M users at the time of LLaMa-2’s release.\n",
      "\n",
      "LLaMa-2: the most generally capable and publicly accessible LLM?\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Human evaluation of LLaMa-2 helpfulness vs. other open source models\n",
      "📝 → 📝\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "GPT and LLaMAs win the popularity contest\n",
      "ChatGPT has the highest number of mentions on X (5430 times), followed by GPT-4 and LLaMA. While \n",
      "proprietary, closed-source models get the most attention, there’s an increase in interest in LLMs that are \n",
      "open-source and allow commercial use.\n",
      "ChatGPT\n",
      "GPT-4\n",
      "LLaMA\n",
      "LLaMA 2\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "Trending topics\n",
      "RLHF / Instruction-tuning emerges as the most trending topic since the end of 2022.\n",
      "Scaling laws that researchers developed for all types of ML models generally predict a smooth decrease in a model’s \n",
      "loss as a function of its parameter count and number of training tokens. In contrast, it has often been observed that \n",
      "some of the models’ capabilities actually emerge unpredictably when a given (unpredictable) scale is surpassed. \n",
      "Some call this observation into question: Emergent capabilities might be merely artifacts of researchers’ choice of \n",
      "evaluation metrics. Others are not convinced and offer counterarguments to the points below.\n",
      "\n",
      "● Stanford researchers found that emergent abilities appeared \n",
      "only under metrics that nonlinearly or discontinuously scale \n",
      "the model’s per-token error rate.\n",
      "● For example, >92% of reported emergent abilities on \n",
      "BIG-Bench (a comprehensive LLM benchmark) appeared under \n",
      "one of two discontinuous metrics.\n",
      "● They test their hypotheses on new models and conﬁrm that \n",
      "replacing nonlinear or discontinuous metrics with linear or \n",
      "continuous proxies results in continuous improvements, rather \n",
      "than emerging capabilities. \n",
      "\n",
      "Are emergent capabilities of language models a mirage?\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "The AI community has extensively veriﬁed that when models are trained correctly, their parameter count is a \n",
      "proxy for their capabilities. But these capabilities are sometimes constrained by the size of input that language \n",
      "models can process. Context length has consequently been an increasingly important theme of research.\n",
      "\n",
      "● One of the most alluring promises of LLMs is their few-shot capabilities, i.e. the ability of \n",
      "an LLM to answer a request on a given input without further training on the user’s speciﬁc \n",
      "use case. But that’s hindered by a limited context length due to the resulting compute and \n",
      "memory bottleneck. \n",
      "● Several innovations have been used to increase the context length of LLMs. Some \n",
      "fundamentally make the memory footprint of attention smaller (FlashAttention). Others \n",
      "enable models to train on small contexts but run inference on larger ones (ALiBi) – this is \n",
      "called length extrapolation – at the price of minimal ﬁnetuning and removing positional \n",
      "encodings. Other techniques worth looking into include RoPE and Positional Interpolation.\n",
      "● Among long-context LLMs: Anthropic’s Claude with 100K, OpenAI’s GPT-4 with 32K, \n",
      "MosaicML MPT-7B with 65K+, LMSys’s LongChat with 16K. But is context all you need?\n",
      "\n",
      "Context length is the new parameter count\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "The race to the highest context length relies on the hypothesis that a larger context length will result in \n",
      "improved performance for downstream tasks. Research from Samaya.ai, UC Berkeley, Stanford, and LMSYS.org \n",
      "calls this hypothesis into question: When input length is long, even the best available language models can fail \n",
      "on some multi-document question answering and key-value retrieval tasks.\n",
      "\n",
      "● The researchers found that the models’ performance was better when the relevant information for the task \n",
      "occurred in the beginning or in the end of the input, with a more or less dramatic dip in the middle \n",
      "depending on the model. They also found that model performance decreased as input length increased.\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Lost in the Middle: long contexts (mostly) don’t live up to the expectations\n",
      "● The researchers examined the \n",
      "performance of open models \n",
      "MPT-30B-Instruct (8K-token length) and \n",
      "LongChat-13B (16K), and closed ones \n",
      "gpt-3.5 (16K) Claude 1.3 (8K) and Claude \n",
      "1.3-100K. They found that proprietary \n",
      "models struggled less than open ones.\n",
      "📝 → 📝\n",
      "● FlashAttention introduces a signiﬁcant memory saving by making attention linear instead of quadratic in \n",
      "sequence length. FlashAttention-2 further improves computing the attention matrix by having fewer non-matmul \n",
      "FLOPS, better parallelism and better work partitioning. The result is a 2.8x training speedup of GPT-style models.\n",
      "● Reducing the number of bits in the parameters reduces both the memory footprint and the latency of LLMs. The \n",
      "case for 4-bit precision: k-bit Inference Scaling Laws shows across a variety of LLMs that 4-bit quantisation is \n",
      "universally optimal for maximizing zero-shot accuracy and reducing the number of bits used.\n",
      "● Speculative decoding enables decoding multiple tokens in parallel through multiple model heads rather than \n",
      "forward passes, speeding up inference by 2-3X for certain models.\n",
      "● SWARM Parallelism is a training algorithm designed for poorly connected and unreliable devices. It enables \n",
      "training billion-scale LLMs on low bandwidth networks and low-power GPUs while achieving high training \n",
      "throughput.\n",
      "\n",
      "Keeping up with high memory demands\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      " Increased context length and large datasets require architectural innovations. \n",
      "📝 → 📝\n",
      "In a still largely exploratory work, Microsoft researchers showed that when small language models (SLMs) are \n",
      "trained with very specialized and curated datasets, they can rival models which are 50x larger. They also ﬁnd \n",
      "that these models’ neurons are more interpretable.\n",
      "\n",
      "● One hypothesis for why small models often aren’t as good as large ones, even on narrow tasks, is that they are \n",
      "“overwhelmed” when trained on very large, uncurated datasets.\n",
      "\n",
      "Can small (with good data) rival big?\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Assisted by GPT-3.5 and GPT-4, researchers generated \n",
      "TinyStories, a synthetic dataset of very simple short stories but \n",
      "that capture English grammar and general reasoning rules. They \n",
      "then trained SLMs on TinyStories and showed that GPT-4 (which \n",
      "was used as an evaluation tool) preferred stories generated by a \n",
      "28M SLM to those generated by GPT-XL 1.5B.\n",
      "● In another work from the same group, the researchers selected a dataset of 7B tokens comprised of \n",
      "high-quality code and synthetic GPT-3.5-generated textbooks and exercises. They then trained several SLMs \n",
      "on this dataset, including the 1.3B parameters phi-1, which they claim is the only sub-10B parameter model \n",
      "to achieve >50% on HumanEval. They have since published the improved phi-1.5 version.\n",
      "📝 → 📝\n",
      "In 2022, we predicted: “A SOTA LM is trained on 10x more data points than Chinchilla, proving data-set scaling \n",
      "vs. parameter scaling”. Although OpenAI didn’t conﬁrm – and we probably won’t know anytime soon – a sort of \n",
      "consensus seems to be reached among experts about leaked information on the model size, architecture, and \n",
      "the dollar cost of GPT-4. GPT-4 was reportedly trained on ~13 trillion tokens, 9.3x more tokens than Chinchilla. \n",
      "\n",
      "● The tiny corp founder George Hotz presented the most plausible rumour: “Sam Altman won’t tell you that GPT-4 \n",
      "has 220B parameters and is a 16-way mixture model with 8 sets of weights”, and Soumith Chintala, PyTorch \n",
      "co-founder, conﬁrmed. Neither the total size of the model nor using a Mixture of Experts model is unheard of. If \n",
      "the rumours are to be believed, no fundamental innovation underpins GPT-4’s success.\n",
      "\n",
      "2022 Prediction: language models trained on huge amounts of data\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "meme\n",
      "truth?\n",
      "📝 → 📝\n",
      "Assuming current data consumption and production rates will hold, research from Epoch AI predicts that “we \n",
      "will have exhausted the stock of low-quality language data by 2030 to 2050, high-quality language data before \n",
      "2026, and vision data by 2030 to 2060.” Notable innovations that might challenge the hypotheses in the article \n",
      "are speech recognition systems like OpenAI’s Whisper that could make all audio data available for LLMs, as well \n",
      "as new OCR models like Meta’s Nougat. It is rumored that plenty of transcribed audio data has already been \n",
      "made available to GPT-4.\n",
      "\n",
      "\n",
      "Are we running out of human-generated data?\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "Another perspective that improving generating models open is expanding the pool of available training data \n",
      "via AI-generated content. We’re nowhere near a deﬁnitive answer: Synthetic data is becoming more helpful, but \n",
      "there is still evidence showing that in some cases generated data makes models forget.\n",
      "\n",
      "● Despite the seemingly inﬁnitely proprietary and publicly available data, the largest models are actually running \n",
      "out of data to train on, and testing the limits of scaling laws. One way to alleviate this problem (which has been \n",
      "extensively explored in the past) is to train on AI-generated data, whose volume is only bounded by compute.\n",
      "\n",
      "Breaking the data ceiling: AI-generated content\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Researchers from Google ﬁne-tune the Imagen text-to-image model for \n",
      "class-conditional ImageNet, then generated one to 12 synthetic versions \n",
      "of ImageNet on which they trained their models (in addition to the \n",
      "original ImageNet). They showed that increasing the size of the synthetic \n",
      "dataset monotonically improved the model’s accuracy.\n",
      "● Other researchers showed that the compounding errors from training on \n",
      "synthetic text online may result in model collapse, “where generated data \n",
      "end up polluting the training set of the next generation of models”. The way \n",
      "forward might be carefully-controlled data-augmentation (so as usual).\n",
      "📝 → 📝\n",
      "📝 → 🖼 \n",
      " As text and image generative models become ever more capable, the longstanding problem of identifying what \n",
      "is AI generated and whether it comes from a copyrighted source becomes increasingly harder to solve. \n",
      "\n",
      "● Research from the University of Maryland proposes a new technique for watermarking proprietary language \n",
      "model output, i.e. “inserting a hidden pattern in text that is imperceptible to humans, while making the text \n",
      "algorithmically identiﬁable as synthetic.” The idea is to choose a few tokens at random, and increase the \n",
      "probability of the LM generating them. They devise an open-source algorithm that involves a statistical test \n",
      "which allows them to conﬁdently detect watermarks.\n",
      "● Google DeepMind launched SynthID, a tool which embeds a digital watermark directly into image pixels. While \n",
      "imperceptible to the human eye, it can identify Imagen-generated images.\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Disentangling the real and the fake, and surfacing the real behind the fake\n",
      "● Researchers from Google, DeepMind, ETH, Princeton, and UC Berkeley showed that \n",
      "Stable Diffusion (a model used by Stability AI among others) memorizes individual \n",
      "images from training and emits them at generation time. The authors are able to \n",
      "extract 1,000+ images, including ones with trademarked company logos. They \n",
      "further show that diffusion models are much more prone to generating images \n",
      "from their training set than other generative models like GANs.\n",
      "If we can’t have more original training data, why not train more on what we have? Conﬂicting research \n",
      "indicates that the answer is, as always, it depends: Training for one or two epochs will generally be optimal; In \n",
      "some cases, pushing for a few more epochs can help; But too many epochs generally equals overﬁtting.\n",
      "\n",
      "● Before the large-scale deep learning era (say post GPT-2), most models were trained multiple epochs over a \n",
      "given dataset. But as the size of models grew larger, training for multiple epochs almost always resulted in \n",
      "overﬁtting, prompting most practitioners to train for a single epoch on the available data (which for once, is the \n",
      "theoretically optimal thing to do).\n",
      "\n",
      "Breaking the data ceiling: overtraining\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "Vibe check: evaluating general-purpose LLMs leaderboards and “vibes”\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The motto of the HELM benchmark is to evaluate as many things as you can, leaving the choice of speciﬁc \n",
      "tradeoffs to users. It evaluates models on 42 scenarios (benchmarks) on 59 metrics. Categories for metrics \n",
      "include accuracy, robustness, fairness, bias, etc.\n",
      " As both open and closed LLMs multiply, users are left with a plethora of non-differentiated LLMs trained on more \n",
      "or less the same data. Based on challenging benchmarks, Stanford’s HELM leaderboard and Hugging Face’s LLM \n",
      "Benchmark seem to be the current standard for comparing model capabilities. But beyond benchmarks or \n",
      "combinations thereof, with such ﬂexible models, users seem to still prefer the more subjective… vibes.\n",
      "● Contrary to HELM which includes both open and closed \n",
      "LLMs, Hugging Face’s benchmark only compares open \n",
      "LLMs, but it seems to be evaluated more often than HELM \n",
      "(evaluating the largest models is also much more costly).\n",
      "● Despite relatively dynamic benchmarks, according to the \n",
      "omniscient machine learning source of truth, X/Twitter, \n",
      "users tend to disregard leaderboards, and only trust their \n",
      "“vibes” when applying LLMs to their speciﬁc use-case.\n",
      "📝 → 📝\n",
      "● Both Unnatural CodeLLaMa and WizardCoder are trained not only on large pre-training coding dataset, but also \n",
      "using additional LM-generated instruction ﬁnetuning techniques adapted to code data. Meta used their \n",
      "Unnatural Instructions while WizardLM used their EvolInstruct. Notably, CodeLLaMa is trained in a way that \n",
      "enables the model to do inﬁlling (rather than only completion from past text), and all the CodeLLaMa models \n",
      "were released except for Unnatural CodeLLaMa.\n",
      "● Smaller LMs for code (including replit-code-v1-3b and StarCoder 3B) offer both low latency and good \n",
      "performance on code completion tasks. Their support for inference at the edge (e.g., ggml on Apple Silicon) \n",
      "have fostered the development of privacy-aware alternatives to GitHub Copilot.\n",
      " The leader in terms of coding abilities is unsurprisingly GPT-4, with Code Interpreter or now Advanced Data \n",
      "Analysis leaving users in awe. Open alternatives like WizardLM’s WizardCoder-34B and Unnatural CodeLLaMa \n",
      "hold up with ChatGPT in coding benchmarks, but their performance in production is still TBD.\n",
      "\n",
      "\n",
      "State of LMs for code\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → </>\n",
      "DeepMind released AlphaDev, a deep RL agent based on AlphaZero that optimizes low-level Assembly code used \n",
      "to turn high-level code (e.g. in C++ or Python) into machine-readable binary code. Through simple deletes and \n",
      "edits to an existing algorithm, AlphaDev found a method that speeds up sorting small sequences by up to 70%.\n",
      "\n",
      "● AlphaZero had been used to reach superhuman levels in \n",
      "chess, Go, and shogi, or even to improve chip design. \n",
      "● AlphaDev reformulates code optimization as an RL \n",
      "problem: At time t, the state is a representation of the \n",
      "generated algorithm and of memory and registers; the \n",
      "agent then writes new instructions or deletes new ones; its \n",
      "reward depends on both correctness and latency.\n",
      "● The discovered algorithms for sort3, sort4, and sort5, led to \n",
      "improvements of ~1.7% for sequences larger than 250K. \n",
      "These were open-sourced in the ubiquitous LLVM library.\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Interestingly, through careful prompting, a researcher managed to make GPT-4 come up with a similar (very \n",
      "simple) optimization to AlphaDev’s for sort3. \n",
      "📝 → </> \n",
      "AlphaZero is DeepMind’s gift that keeps on giving, now for low-level code optimization\n",
      "The quality of a prompt highly inﬂuences task performance. Chain of Thought prompting (CoT) asks the LLM to \n",
      "additionally output intermediate reasoning steps which gives a boost in performance. Tree of Thought (ToT) further \n",
      "improves on that by sampling multiple times and representing the “thoughts” as nodes in a tree structure.\n",
      "\n",
      "● The tree structure of a ToT can be explored with a variety of search algorithms. In order to leverage this search, \n",
      "the LLM also needs to assign a value to node, for instance by classifying it as one of sure, likely or impossible. \n",
      "Graph of Thought (GoT) turns this reasoning tree into a graph by combining similar nodes.\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Where are we prompting? Take a deep breath…it’s getting sophisticated\n",
      "📝 → 📝 \n",
      "● It turns out that LLMs are also great prompt engineers. \n",
      "Auto-CoT matches or exceeds the performance of CoT on 10 \n",
      "reasoning tasks. Automatic Prompt Engineer (APE) shows the \n",
      "same on 19/24 tasks. APE-engineered prompts are also able to \n",
      "steer models towards truthfulness and/or informativeness. \n",
      "Optimization by Prompting (OPRO) shows that optimized \n",
      "prompts outperform human-designed prompts on GSM8K and \n",
      "Big-Bench Hard by a signiﬁcant margin, sometimes over 50%.\n",
      "Downstream tasks are highly dependent on underlying LLM performance. However, changes to the same version \n",
      "of GPT models are not announced by OpenAI, despite them being continuously updated. The same LLM version \n",
      "has been reported by users to have drastically different performance over time. Everyone had to continuously \n",
      "monitor performance as well as update carefully curated prompts.\n",
      "\n",
      "● How is ChatGPT’s Behaviour Changing over Time? report shows that March 2023 and June 2023 versions of GPT3.5 \n",
      "and GPT4 varied in performance on tasks like math questions (ﬁgure below), sensitive questions, opinion surveys, \n",
      "knowledge questions, generating code, US Medical License tests and visual reasoning.\n",
      "\n",
      "Prompt engineering trial and error \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "The most immediate way LLMs can have an impact on the economy today is when they are enabled to execute \n",
      "calls to diverse external tools. The most obvious use tool is a web browser, allowing a model to stay up to date, \n",
      "but practitioners are ﬁne-tuning language models on API calls to enable them to use virtually any possible tool.\n",
      "\n",
      "● One example of tool-using LLMs is Meta and Universitat Pompeu Fabra’s Toolformer, where researchers train a \n",
      "GPT-J-based model in a self-supervised manner“to decide which APIs to call, when to call them, what arguments to \n",
      "pass, and how to best incorporate the results into future token prediction.” Notably, during training, Toolformer \n",
      "samples API calls and only retains the ones which result in reducing the training loss.\n",
      "\n",
      "Welcome, Agent Smith: LLMs are learning to use software tools\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Some models are more narrowly focused, like Google’s Mind’s eye, where models \n",
      "run a physics simulation to answer physics reasoning questions, while others \n",
      "extended this approach to tens of thousands of possible external tools.\n",
      "● LLMs which are able to use external tools are now commonly referred to as \n",
      "“agents”. Stepping out from academic research, we have seen multiple tools \n",
      "devised by industry and the open source community, most notably ChatGPT \n",
      "plugins, Auto-GPT and BabyAGI.\n",
      "📝 → 🛠\n",
      "Capable of code generation and execution, LLMs can be powerful planning agents in open-ended worlds. The best \n",
      "example of this is Voyager, a GPT-4 based agent capable of reasoning, exploration and skill acquisition in \n",
      "Minecraft. \n",
      "\n",
      "● By iteratively prompting GPT-4 (LLMs still struggle at one-shot code generation), Voyager produces executable \n",
      "code to complete tasks. Note that most likely GPT-4 has seen a signiﬁcant amount of Minecraft related data, so \n",
      "this approach might not generalise to other games.\n",
      "Open-ended learning with LLMs\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The agent interacts with the environment through explicit \n",
      "javascript code via the MineCraft API. If the generated code \n",
      "succeeds at the task, it is then stored as a new ‘skill’, otherwise \n",
      "GPT-4 gets prompted again with the error.\n",
      "● GPT-4 generates the tasks curriculum based on Voyager’s state \n",
      "to encourage it to solve progressively harder tasks.\n",
      "● Without any training, Voyager obtains 3.3x more unique items, \n",
      "travels 2.3x longer distances, and unlocks key tech tree \n",
      "milestones up to 15.3x faster than prior SOTA.\n",
      "📝 → 🛠\n",
      "Reasoning with language model is planning with a world model\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The world model can generate an action as well as predict the next \n",
      "state reached by taking that action. This produces a reasoning trace \n",
      "which makes the LM more coherent then Chain of Thought \n",
      "methods which predict next actions but not next world states.\n",
      "● The rewards are also obtained from the LM and used to maintain a \n",
      "state-action value function for planning with MCTS.\n",
      "● While being signiﬁcantly more expensive, RAP outperforms \n",
      "Chain-of-Thought reasoning approaches on plan generation, math \n",
      "reasoning and logical reasoning. RAP on LLaMA-33B even \n",
      "outperforms CoT on GPT-4 in a setting of Blocksworld. \n",
      "📝 → 🛠 \n",
      " Reasoning has been traditionally thought of as searching a space of possible outcomes and picking the best one. \n",
      "By containing so much information about the world, LLMs offer the opportunity of generating this space (often \n",
      "called a world model) in which planning algorithms can explore. Reasoning via Planning (RAP) uses Monte Carlo \n",
      "Tree Search to ﬁnd a high-reward reasoning path efﬁciently.\n",
      "Another text-only agent based on GPT-4 is SPRING. It outperforms state-of-the-art RL baselines in open-world \n",
      "games with no training. It reads a game’s original academic paper and plays the game through an LLM.\n",
      "\n",
      "● RL has been the go-to for game-based problems like Minecraft and Crafter, despite it being limited by the high \n",
      "sample complexity and difﬁculty in incorporating prior knowledge. In contrast, the LLM can processes the latex \n",
      "source of the paper and reasons through a QA framework (directed acyclic graph with questions as nodes and \n",
      "dependencies as edges) to take an environment action. \n",
      "\n",
      " GPT-4 out-performs RL algorithms by studying papers and reasoning\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 🛠\n",
      "In a new Visual Instruction Benchmark (VisIT-Bench) consisting of 592 queries with human-authored captions \n",
      "vision-language models are tested against human-veriﬁed GPT4 and most come short of expectations.\n",
      "\n",
      "\n",
      "Vision-language models: GPT-4 wins (but API access is still limited)\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "●\n",
      "According to human evaluators the best model is \n",
      "LLaMa-Adapter-v2, despite it only winning against the GPT4 \n",
      "veriﬁed reference captions in 27.4% of the cases on \n",
      "VisIT-Bench.\n",
      "●\n",
      "Earlier this year a multimodal model that stood out was \n",
      "BLIP-2 from Salesforce. It was released early (before GPT4) \n",
      "and had better performance than closed-source Flamingo on \n",
      "VQAv2 while having 54x less trainable parameters. It uses an \n",
      "off-the-shelf frozen LLM, an off-the-shelf frozen pre-trained \n",
      "image encoder and only trains a small transformer. \n",
      "●\n",
      "However its improved variant InstructBLIP has a win rate of \n",
      "only 12.3% against GPT4 reference captions on VisIT-Bench.\n",
      "📝+ 🖼 → 📝\n",
      "Two methods VisProg and ViperGPT show how given an input natural language query about an image, an LLM \n",
      "can decompose this into a sequence of interpretable steps that call predeﬁned API functions for visual tasks.\n",
      "● The visual programming approach aims to build general-purpose vision systems via compositional multi step \n",
      "reasoning instead of end-to-end multitask training. Both methods use entirely off-the-shelf components. \n",
      "\n",
      "\n",
      "Leveraging LLMs and world knowledge for compositional visual reasoning \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● An API for visual primitives calls into existing SOTA models (e.g. semantic \n",
      "segmentation, object detection, depth estimation). \n",
      "● ViperGPT uses Codex to directly generate python programs based on the \n",
      "API which can be executed using a python interpreter. VisProg prompts \n",
      "GPT-3 with examples of pseudocode instructions and interprets them as a \n",
      "‘visual program,’ relying on LLM in-context learning from examples. \n",
      "● World knowledge in LLMs from training on internet scale data is shown to \n",
      "aid in visual reasoning tasks (e.g. querying for non alcoholic drink in an \n",
      "image based on detected brand). Both methods show state-of-the-art \n",
      "results across various complex visual tasks. \n",
      " \n",
      "📝+ 🖼 → 📝\n",
      "LINGO-1 is Wayve’s vision-language-action model that provides driving commentary, such as information about \n",
      "the driving behaviour or the driving scene. It can also answer questions in a conversational manner. LINGO-1 \n",
      "can be a game changer in terms of explainability of end-to-end driving models as well improve reasoning and \n",
      "planning.\n",
      "\n",
      "\n",
      "Leveraging LLMs for autonomous driving\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝+ 🖼 → 📝\n",
      "PaLM-E is a 562-billion parameter, general-purpose, embodied generalist model trained on vision, language and \n",
      "robot data. It can control a manipulator in real time while also setting a new SOTA on a VQA benchmark. Given its \n",
      "embodied intelligence advantage, PaLM-E is better at pure language tasks (particularly the ones involving \n",
      "geo-spatial reasoning) than text-only language models.\n",
      "\n",
      "\n",
      "PaLM-E: a foundation model for robotics\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "●\n",
      "The model combines PaLM-540B \n",
      "and ViT-22B and enables as input \n",
      "text, images and robot states \n",
      "which are encoded into the same \n",
      "space as word token embeddings \n",
      "and then fed into a language \n",
      "model to perform next token \n",
      "prediction. \n",
      "📝+ 🖼+ 🤖 → 📝\n",
      "Vision-language models can be ﬁne-tuned all the way to low-level policies showing impressive performance in \n",
      "manipulating objects. They also retain their ability to reason about web-scale data.\n",
      "\n",
      "●\n",
      "RT-2 represents actions as tokens and trains vision-language-action models. Rather than naive ﬁnetuning on \n",
      "robot data only, RT-2 co-ﬁnetunes PaLI-X and PaLM-E on robot actions (6-DoF positional and rotational \n",
      "displacement of the robot end-effector).\n",
      "\n",
      "From vision-language models to low-level robot control: RT-2\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "●\n",
      "Internet-scale training enables generalisation \n",
      "to novel objects, interpreting commands not \n",
      "present in the robot training data and \n",
      "semantic reasoning (ﬁguring out what object \n",
      "to pick as an improvised hammer).\n",
      "●\n",
      "For efﬁcient real-time inference, RT-2 models \n",
      "are deployed in a multi-TPU cloud service. The \n",
      "largest RT-2 model (55B parameters) can run \n",
      "at a frequency of 1-3Hz.\n",
      "📝+ 🖼+ 🤖 → 📝\n",
      "RoboCat is a foundation agent for robotic manipulation that can generalise to new tasks and new robots in \n",
      "zero-shot or few-shot (100-1000 examples). Impressive real-time performance on a variety of platforms.\n",
      "\n",
      "●\n",
      "It’s built on top of DeepMind’s multi-modal, multi-task and multi-embodiment Gato. It uses a frozen VQ-GAN \n",
      "tokenizer trained on a variety of vision and control datasets. While Gato only predicted actions, RoboCat \n",
      "additionally predicts future VQ-GAN tokens. \n",
      "●\n",
      "In terms of policy learning, the paper only mentions behaviour cloning. RoboCat is ﬁne-tuned with few \n",
      "demonstrations (via teleoperation) and re-deployed to generated new data for a given task, self-improving in \n",
      "subsequent training iterations.\n",
      "●\n",
      "RobotCat can operate 36 real robots with different action speciﬁcations, in 253 tasks on 134 real objects at an \n",
      "impressive speed (20Hz).\n",
      "\n",
      "From vision-language models to low-level robot control: RoboCat\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝+ 🖼+ 🤖 → 📝\n",
      "This is a ﬁrst time win for a robot in a competitive sport (ﬁrst-person view drone racing). Swift is an autonomous \n",
      "system that can race a quadrotor at the level of human world champions using only onboard sensors and \n",
      "computation. It won several races against 3 champions and had the fastest recorded time.\n",
      "\n",
      "●\n",
      "Swift uses a combination of learning-based and more \n",
      "traditional techniques. It combines a VIO estimator with a \n",
      "gate detector that estimates global position and \n",
      "orientation of the drone through a Kalman ﬁlter to obtain \n",
      "an accurate estimation of the robot’s state.\n",
      "●\n",
      "Swift’s policy is trained using on-policy model-free deep \n",
      "reinforcement learning in simulation with a reward that \n",
      "combines progress towards the next gate and keeping it \n",
      "in the ﬁeld of view (this increases pose estimation \n",
      "accuracy). The racing policy transfers well from sim to real \n",
      "when accounting for uncertainty in perception. \n",
      "\n",
      "An autonomous system that races drones faster than human world champions\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Map-building is an emergent phenomenon in the course of AI agents learning to navigate. It explains why we \n",
      "can feed neural networks images with no explicit maps and can predict navigation policies.\n",
      "\n",
      "● The Emergence of Maps in the Memories of Blind Navigation Agents shows \n",
      "that giving an agent knowledge of only ego-motion (change in agent’s \n",
      "location and orientation as it moves) and goal location is sufﬁcient to \n",
      "successfully navigate to the goal. Note that this agent does not have any \n",
      "visual information as input and yet its success rates compared to \n",
      "‘sighted’ agents are very similar, only efﬁciency differs.\n",
      "● The model doesn’t have any inductive bias towards mapping and is \n",
      "trained with on-policy reinforcement learning. The only mechanism that \n",
      "explains this ability is the memory of the LSTM.\n",
      "● It is possible to reconstruct metric maps and detect collisions solely \n",
      "from the hidden state of this agent.\n",
      "\n",
      "The emergence of maps in the memories of blind navigation agents\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Meta trained an AI agent to play a popular multiplayer strategy game called Diplomacy, which involves planning \n",
      "and negotiating in natural language with other players over multiple rounds. CICERO achieved double the \n",
      "average score of human players online and ranked in the top 10% players who played more than one game.\n",
      "\n",
      "● Fast parallel progress in strategic planning and language modeling allows for \n",
      "potentially great advancements at the intersection, with applications in human-AI \n",
      "cooperation. Meta tackles the game of Diplomacy as a benchmark for such progress.\n",
      "● CICERO uses dialogue history between players as well as the board state and its history \n",
      "to begin predicting what everyone will do. It then iteratively reﬁnes these predictions \n",
      "using planning, then decides according to a policy which action it intends to take. \n",
      "CICERO then generates and ﬁlters candidate messages to communicate with players.\n",
      "● The controllable dialogue model it uses is based on a 2.7B-params BART-like model \n",
      "ﬁne-tuned on >40K online games of Diplomacy. CICERO uses a new iterative planning \n",
      "algorithm based on piKL which improves the predictions of other players’ moves after \n",
      "dialoguing with them.\n",
      "\n",
      "CICERO masters natural language to beat humans at Diplomacy\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 📝\n",
      "Similar to last year (Slide 33), the race is between video diffusion and masked transformer models (although \n",
      "algorithmically the two are very similar). Last year’s Make-a-video and Imagen were based on diffusion while \n",
      "Phenaki was based on a bidirectional masked transformer. \n",
      "\n",
      "● VideoLDM is a latent diffusion model capable of high-resolution video generation (up to 1280 x 2048!). They \n",
      "build on pre-trained image diffusion models to turn them into video generators by temporally ﬁne-tuning with \n",
      "temporal alignment layers.\n",
      "● MAGVIT is a masked generative video transformer. Similarly to Phenaki, it uses a 3D tokeniser to extract \n",
      "spatio-temporal tokens. It introduces a novel masking approach. It currently has the best FVD on video \n",
      "generation benchmarks and it’s 250x faster than video diffusion.\n",
      "\n",
      "The text-to-video generation race continues\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 🎥\n",
      "Last year saw the emergence of a host of text-image generation models: DALLE-2, Imagen, Parti, Midjourney, \n",
      "Stability and more. But controlling the generation requires experimenting extensively with prompts and custom \n",
      "syntax. This year has seen new methods enabling co-pilot style capability for image generation and editing. \n",
      "\n",
      "● InstructPix2Pix, leverages pre-trained GPT3 and \n",
      "StableDiffusion to generate a large dataset of {input image, \n",
      "text instruction, generated image} triplets to train a \n",
      "supervised conditional diffusion model. Editing then happens \n",
      "in a feed-forward way without any per image ﬁne \n",
      "tuning/inversion, enabling modiﬁcations in seconds.\n",
      "● Masked inpainting methods such as Imagen Editor require \n",
      "providing the model with an overlay or “mask” to indicate the \n",
      "region to modify, alongside text instructions. \n",
      "● Building on these approaches, startups such as Genmo AI’s \n",
      "“Chat” provide a co-pilot style interface for image generation \n",
      "with text-guided semantic editing. \n",
      "\n",
      "Instruction based editing assistants for text-image generation\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 + 🖼 → 🖼\n",
      "A new NeRF contender based on 3D Gaussians shows impressive quality while also enabling real-time rendering.\n",
      " \n",
      "\n",
      "\n",
      "Welcome 3D Gaussian Splatting\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "MipNeRF360 [Barron ‘22]\n",
      "0.06 fps\n",
      "Train: 48h, PSNR: 27.69\n",
      "3D Gaussian Splatting\n",
      "134 fps\n",
      "Train: 41min, PSNR: 27.21\n",
      "●\n",
      "Instead of learning the parameters of a neural network, 3D \n",
      "Gaussian Splatting learns millions of Gaussian distributions \n",
      "(one for each 3D point) and performs rasterisation by \n",
      "calculating the contribution each gaussian makes to each pixel \n",
      "in the ﬁnal image.\n",
      "●\n",
      "Areas that need more representational power use more \n",
      "Gaussians, while avoiding unnecessary computation in empty \n",
      "space, which is why, similarly to NeRFs, scenes look so \n",
      "beautifully detailed.\n",
      "●\n",
      "It’s now possible to render high-quality real-time (≥ 100 fps) \n",
      "novel-views at 1080p resolution.\n",
      " 🖼 → 📦 \n",
      "*Note that Zip-NeRF has a training time of 53min and a \n",
      "PSNR of 28.54 on the same dataset (Multiscale 360).\n",
      "NeRF-based generative models are a promising direction for large scale creation of 3D assets. NeRFs not only have \n",
      "improved in speed and quality (see HyperDiffusion, MobileNeRF, Neurolangelo and DynIBAR) but also enabled GenAI \n",
      "to model 3D geometry.\n",
      "\n",
      "\n",
      "NeRFs meet GenAI\n",
      "●\n",
      "DreamFusion and Score Jacobian Chaining were the ﬁrst methods to use a pretrained 2D text-to-image diffusion \n",
      "model to perform text-to-3D synthesis. Early attempts showed cartoonish-looking 3D models of single objects.\n",
      "●\n",
      "RealFusion ﬁnetunes the diffusion prior on a speciﬁc image to increase that image’s likelihood.\n",
      "●\n",
      "SKED only alters a selected region of a NeRF provided through a few guiding sketches. They preserve the quality \n",
      "of the base NeRF and ensure that the edited region respects the semantics of a text prompt.\n",
      "●\n",
      "Instruct-Nerf2Nerf edits an entire NeRF scene rather than a region or generating from scratch. They apply a latent \n",
      "diffusion model on each input image and iteratively update the NeRF scene ensuring it stays consistent.\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      " 🖼 , 📝 → 📦\n",
      "Zero-shot depth models have recently been used as conditioning for better image generation. This only requires \n",
      "relative depth prediction, while other downstream applications such as robotics require metric depth which so \n",
      "far has not generalised well across datasets.\n",
      "\n",
      "\n",
      "Zero-shot metric depth is here\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● “ZeroDepth: Towards Zero-Shot Scale-Aware Monocular Depth Estimation” is able to predict metric depth for images \n",
      "from different domains and different camera parameters. They jointly encode image features and camera \n",
      "parameters which enables the network to reason over the size of objects and train in a variational framework. The \n",
      "depth network ends up learning ‘scale priors’ that can be transferred across datasets.\n",
      "● “ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth” is a relative depth model with an additional \n",
      "module ﬁne-tuned on metric depth. This is the ﬁrst model to train on multiple datasets without a signiﬁcant drop \n",
      "in performance and able to generalise across both indoor and outdoor domains.\n",
      " 🖼 → 📦\n",
      "● Taking inspiration from large language models which are pre-trained on vast datasets and exhibit zero-shot \n",
      "capabilities via prompting, Meta researchers set out to build a model that enables general promptable \n",
      "segmentation: given any prompt, the model should be able to identify and segment any object in any image.\n",
      " Meta introduced a large-scale project called “Segment Anything” which included the release of 1B segmentation \n",
      "masks on a 11M image dataset (SA-1B), and a segmentation model (SAM) with an Apache 2.0 commercial use \n",
      "license. Meta tested SAM on 23 out of domain image datasets outperforming existing SoTA on 70%+ of cases. \n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Segment Anything: a promptable segmentation model with zero-shot generalisation\n",
      "● The model has two components: (i) An heavyweight encoder (ViT) to compute \n",
      "a one-time image embedding, (ii) a lightweight interactive module (that can \n",
      "run on CPU in a browser) consisting of a prompt encoder that embeds the \n",
      "user prompt, and mask decoder that predicts the segmentation masks.\n",
      "● A model-in-the-loop data-engine was used to generate the training data, with \n",
      "the ﬁnal SA-1B generated entirely automatically by applying SAM.\n",
      "● Through prompt engineering, SAM can be applied to other tasks including \n",
      "edge detection, object proposal generation, and instance segmentation and \n",
      "preliminary results were shown combining SAM + CLIP for text prompts.\n",
      "● It is the ﬁrst work to close the gap between self-supervised and weakly supervised approaches. DINOv2 features are \n",
      "shown to contain information about object parts as well as semantic and low level understanding of images.\n",
      " DINOv2 is a self-supervised Vision Transformer model from Meta, producing universal visual features that can be \n",
      "used across a variety of image level (e.g. classiﬁcation) and pixel level (e.g. segmentation) tasks without \n",
      "ﬁne-tuning and are competitive with SOTA open-source weakly supervised alternatives.\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "DINOv2: the new default computer vision backbone\n",
      " \n",
      "● The authors made the training of self-supervised learning models \n",
      "more stable through additional regularisation methods and reduced \n",
      "the memory requirements, which enabled training larger models on \n",
      "more data for longer. They also provide compressed versions of the \n",
      "models obtained through distillation.\n",
      "● Although any image can be used for training, a key component was \n",
      "curating the dataset and automatically balancing it across concepts \n",
      "(keeping 142M out of 1.2B source images). Re-visit this slide.\n",
      "● DINOv2 features can be used with linear classiﬁers to obtain strong \n",
      "results across many visual tasks.\n",
      "● Pangu-Weather is a 3D deep learning model with \n",
      "Earth-speciﬁc priors trained on 39 years of global \n",
      "data that can generate medium-range global \n",
      "weather for. The system can be used for more \n",
      "accurate early-stage cyclone tracking vs status quo.\n",
      " Skilful short term precipitation predictions (nowcasting) today are blurry, prone to dissipation and are slow. \n",
      "Medium-range global weather forecasts using the accurate numerical weather prediction method is \n",
      "computationally expensive. For both problems, learned methods and physics-informed models that incorporate \n",
      "relevant priors are able to deliver performance improvements preferred by professional meteorologists. New \n",
      "benchmark datasets such as Google’s WeatherBench 2 help data-driven weather model development. \n",
      "\n",
      "\n",
      "More accurate weather predictions, in the now(casts) and the longer ranges\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● NowcastNet is a nonlinear model that uses physical \n",
      "ﬁrst principles and statistical-learning methods, \n",
      "uniﬁed under a deep generative model framework. \n",
      "Evaluated by 62 professional meteorologists from \n",
      "across China, the model ranks 1st in 71% of cases \n",
      "against leading methods.\n",
      "New models from Google, Meta, and the open source community signiﬁcantly advance the quality of \n",
      "controllable music generation. \n",
      "\n",
      "● Though not the best in terms of generated music quality, Riffusion was probably the most innovative model. \n",
      "Researchers ﬁne-tuned Stable Diffusion on images of spectrograms, which are then converted into audio clips.\n",
      "● With MusicLM, Google researchers “cast conditional music generation as a hierarchical seq2seq modeling task”. They \n",
      "are able to generate consistent music (@24kHz) over several minutes. Samples are available at \n",
      "https://google-research.github.io/seanet/musiclm/examples/\n",
      "● To our ears, Meta’s MusicGen strikes a better balance between adhering to text descriptions and generating a \n",
      "pleasant melody. It uses a single transformer LM and careful codebook interleaving techniques. Samples: \n",
      "https://ai.honu.io/papers/musicgen/ \n",
      "\n",
      "Another year of progress in music generation\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 → 🎵\n",
      "Designing novel proteins from scratch such that they have desired functions or structural properties, de novo \n",
      "design, is of interest in both research and industry. Inspired by their success in generative modelling of images \n",
      "and language, diffusion models are now applied to de novo protein engineering. \n",
      "\n",
      "\n",
      "Diffusion models design diverse functional proteins from simple molecular speciﬁcations\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● A model called RFdiffusion takes advantage of the high precision, \n",
      "residue-level resolution protein structure prediction capabilities of \n",
      "RoseTTAFold to ﬁne-tune it as the denoising network in a generative \n",
      "diffusion model using noisy structures from the Protein Data Bank. \n",
      "● Similar to AlphaFold 2, RFdiffusion is best trained when the model \n",
      "conditions denoising on previous predictions between timesteps. \n",
      "● RFdiffusion can generate protein backbones with desired features and \n",
      "ProteinMPNN can then be used to design sequences that encode these \n",
      "generated structures. \n",
      "● The model can produce backbone designs for protein monomers, protein \n",
      "binders, symmetric oligomers, enzyme active site scaffolding and more.\n",
      "● This model, Evolutionary Scale Modeling–2 (ESM-2), is used to characterize the structure of \n",
      ">617M metagenomic proteins (found in soil, bacteria, water, etc). ESM-2 (schematic below) \n",
      "offers signiﬁcant speedups compared to AlphaFold-2 (AF2): these results were produced in 2 \n",
      "weeks using a cluster of 2,000 GPUs. \n",
      "● ESMFold is a fully end-to-end single-sequence structure predictor that uses a folding head for \n",
      "ESM-2. ESMFold structures (right) are of AF2-grade quality as measured by TM-score, which is \n",
      "the accuracy of the projection in comparison to the ground truth structure.\n",
      " Atomic-level protein structure can now be directly predicted from amino acid sequences without relying on \n",
      "costly and slow multiple sequence alignment (MSA). To do so, a masked language modeling objective is used \n",
      "over millions of evolutionarily diverse protein sequences to cause biological structure to materialize in the \n",
      "language model because it is linked to the sequence patterns. \n",
      "\n",
      "\n",
      "Learning the rules of protein structure at evolutionary-scale with language models\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Understanding how gene expression changes as a result of stimulating or repressing combinations of genes (i.e. \n",
      "perturbations) is important to unravel biological pathways relevant to health and disease. But combinatorial \n",
      "explosion precludes us from running these experiments in living cells in the lab. Integrating deep learning with \n",
      "a knowledge graph of gene-gene relationships offers a solution. \n",
      "\n",
      "● Graph-enhanced gene activation and repression simulator \n",
      "(GEARS) combines prior experimental knowledge to predict \n",
      "the gene expression outcome given unperturbed gene \n",
      "expression and the applied perturbation. \n",
      "● For example, GEARS can be trained on the gene expression \n",
      "proﬁles postperturbation for one-gene and two-gene \n",
      "experiments (b), and then be tasked with predicting the \n",
      "postperturbation gene expression for 5,460 pairwise \n",
      "combinations (c).\n",
      "\n",
      "Predicting the outcome of perturbing multiple genes without a cell-based experiment\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The AlphaMissense system is built by: (i) training on weak labels from \n",
      "population frequency data, avoiding circularity by not using human \n",
      "annotations; (ii) incorporating an unsupervised protein language modeling task \n",
      "to learn amino acid distributions conditioned on sequence context; and (iii) \n",
      "incorporating structural context by using an AlphaFold-derived system. \n",
      "● AlphaMissense is then used to predict 71M missense variants, saturating the \n",
      "human proteome. Of these, 32% are likely pathogenic and 57% are likely \n",
      "benign. Additional resources include all 216M possible single amino acid \n",
      "substitutions across the 19,233 canonical human proteins.\n",
      " Individual changes in amino acid sequences that result from genetic variation (“missense variants”) can either be \n",
      "benign or result in downstream problems for protein folding, activity or stability. Over 4M of these missense \n",
      "variants have been identiﬁed through human population-level genome sequencing experiments. However, 98% \n",
      "of these variants lack any conﬁrmed clinical classiﬁcation (benign/pathogenic). A new system, AlphaMissense, \n",
      "makes use of AlphaFold predictions and unsupervised protein language modeling to close this gap. \n",
      "\n",
      "\n",
      "Pathogenic or not? Predicting the outcome of all single-amino acid changes\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Google’s Med-PaLM 2 language model is an expert according to the USMLE \n",
      " A year after releasing Med-PaLM, ﬁrst model to exceed a “passing” score on the US Medical Licensing \n",
      "Examination (USMLE), Med-PaLM 2 set a new SOTA result across more datasets as a result of base LLM \n",
      "improvements, medical domain ﬁnetuning and prompting strategies. In a pairwise ranking study on 1,066 \n",
      "consumer medical questions, Med-PaLM 2 answers were preferred over physician answers by a panel of \n",
      "physicians across eight of nine axes in our evaluation framework.\n",
      "📝 → 📝\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Next, Med-PaLM goes multimodal \n",
      " To bridge beyond text-based medical Q&A, Google ﬁrst created MultiMedBench - a 14 task dataset that includes \n",
      "medical Q&A, mammography and dermatology image interpretation, radiology report generation and \n",
      "summarization, and genomic variant calling. This dataset is used to train a large single multitask, multimodal \n",
      "version of MedPaLM with the same set of model weights. The system exhibits novel emergent capabilities such \n",
      "as generalisation to novel medical concepts and tasks. An alternative lighter-weight approach, ELIXR, was also \n",
      "proposed. ELIXR grafts language-aligned vision encoders onto a ﬁxed LLM, which requires less compute to train \n",
      "and shows promise across tasks including visual QA, semantic search, and zero-shot classiﬁcation.\n",
      "📝 + 🖼 → 📝\n",
      "● Like CLIP, PLIP can perform zero-shot classiﬁcation on \n",
      "unseen data, enabling it to distin several key tissue types. \n",
      "● It can also be used to improve text-to-image and \n",
      "image-to-image retrieval of pathology images.\n",
      "● Unlike other machine learning approaches in digital \n",
      "pathology that are predicated on learning from a ﬁxed set \n",
      "of labels, PLIP can be more generally applied and is \n",
      "ﬂexible to the changing nature of diagnostic criteria in \n",
      "pathology. \n",
      "● Compared to CLIP, PLIP has 2-6x better Precision@10.\n",
      " It’s no secret that (quality) data is king for building capable AI systems, and no more so than in domains such as \n",
      "clinical medicine where (quality) data is expensive to produce. This work mines text-image pairs on Twitter to \n",
      "create the OpenPath dataset with 200+ pathology images paired with natural language descriptors. Inspired by \n",
      "OpenAI’s Contrastive Language-Image Pretraining (CLIP) model, the authors create P(athology)LIP. \n",
      "\n",
      "\n",
      "Tweet storm: a SOTA pathology language-image pretrained model from medical Twitter\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "📝 + 🖼 → 📝\n",
      "Computer vision has been shown to be useful for breast cancer screening on mammograms and tuberculosis \n",
      "triaging. However, to enable practical and reliable use in the clinic it is important to know when to rely on a \n",
      "predictive AI model or revert to a clinical workﬂow. \n",
      "\n",
      "\n",
      "Real world-inspired clinical system design for automated medical image analysis\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Complementarity-Driven Deferral to Clinical Workﬂow \n",
      "(CoDoC) learns to decide whether to rely on a predictive AI \n",
      "model’s output or defer to a clinical workﬂow instead. \n",
      "● For breast cancer screening, CoDoC reduces false positives by \n",
      "25% at the same false-negative rate compared to double \n",
      "reading with arbitration in the UK. Importantly, clinical \n",
      "workload is reduced by 66% as a result.\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "AI for science: medicine is growing fastest but mathematics captures the most attention\n",
      "The top 20 scientiﬁc ﬁelds applying AI to accelerate progress include physical, social, life and health sciences. \n",
      "Out of all the highest increase in the number of publications is Medicine. We expect there to be signiﬁcant \n",
      "research breakthroughs in the foreseeable future as a result of AI’s use in the sciences.\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "Most impactful research comes from very few places\n",
      ">70% of the most cited AI papers in the last 3 years have authors from US-based institutions and organisations.\n",
      "Section 2: Industry\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "GPU demand sees NVIDIA print blowout earnings as it enters the $1T market cap club\n",
      "Q2 ‘23 data center revenue was a record $10.32B, up 141% from Q1 ‘23 and up 171% from a year ago. The \n",
      "stock was bearish for 2022 even though annual revenue came in at $27B, a 61.4% increase from 2021. NVIDIA \n",
      "now commands a $1.1T market capitalisation, up from $8.5B (130x) 10 years ago.\n",
      "🤯🚀\n",
      "Selling faster than Coachella: GPUs snapped up from upstart infra providers\n",
      "\n",
      "CoreWeave, Lambda, and Crusoe Cloud, three selected NVIDIA partners that build and run GPU datacenters, \n",
      "together have tens of thousands of GPUs in their ﬂeet. Lambda made 9-ﬁgures $ worth of H100s available in \n",
      "its on-demand cloud and sold out in just over an hour. CoreWeave is one of the largest GPU operators in the \n",
      "market with a scale similar to several hyperscalers. The company is fully booked through the end of the year \n",
      "with their build schedule and are signing contracts in Q1 2024.\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Private companies are shoring up NVIDIA GPUs and wielding them as a competitive edge\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Footballers Compute is the new oil in Gulf States?\n",
      "Saudi Arabia’s King Abdullah University of Science and Technology (Kaust) has allegedly purchased >3,000 \n",
      "H100s to build a supercomputer, Shaheen III, that should be operational by end of 2023. Its LLM-focused \n",
      "researchers are primarily Chinese nationals that cannot access the US because their universities are restricted. \n",
      "Meanwhile, the United Arab Emirates’ Technology Innovation Institute in Masdar City, which developed the \n",
      "Falcon LLM, is also said to be procuring compute resources from NVIDIA. Finally, Abu Dhabi-based G42 entered \n",
      "into a deal with US-based Cerebras to procure up to $900M worth of the company’s Wafer-scale compute \n",
      "systems and build 9 interconnected AI supercomputers. There is likely much spend more to come…\n",
      "Compute Index: NVIDIA A100 clusters\n",
      "\n",
      "The number of large-scale NVIDIA A100 GPU clusters has grown since last year, particularly at Tesla and \n",
      "Stability, as well as new clusters at Hugging Face.\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Compute Index: NVIDIA H100 clusters\n",
      "\n",
      "It’s early days, but private and public companies are announcing new H100 infrastructure for large-scale model \n",
      "training. As of writing, Google and Inﬂection are not yet at full scale and we understand others including \n",
      "OpenAI, Anthropic, Meta, Character.ai, Adept, Imbue, and more have signiﬁcant capacity. We expect more to \n",
      "come online soon. \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "NVIDIA chips are used 19x more in AI research papers than all alternative chips combined \n",
      "\n",
      "In last year’s report, we began tracking the utilization of speciﬁc semiconductors in AI research papers. We \n",
      "found that NVIDIA chips were cited vastly more than alternatives. In 2023, NVIDIA is even more popular: 31x \n",
      "more than FPGAs and 150x more than TPUs. \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "31x\n",
      "150x\n",
      "NVIDIA chips have remarkably long lifetime value: 5 years from launch to peak popularity\n",
      "\n",
      "In 2023, all eyes were on NVIDIA’s new H100 GPU, the more powerful successor to the A100. While H100 \n",
      "clusters are being built (not without hiccups), researchers are relying on the V100, A100 and RTX 3090. It is \n",
      "quite remarkably how much competitive longevity NVIDIA products have: the V100, released in 2017, is still \n",
      "the most commonly used chip in AI research. This suggests A100s, released in 2020, could peak in 2026 when \n",
      "the V100 is likely to hit its trough. The new H100 could therefore be with us until well into the next decade!\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "While NVIDIA is king, Cerebras ramps amongst the challenger crop\n",
      "\n",
      "Cerebras, creators of the largest AI chip in the world, engaged in several open source model training and \n",
      "dataset creation projects, which helped it gain traction versus its competitors with researchers. Overall, there’s \n",
      "still a long road to climb for NVIDIA contenders. \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Hyperscalers scale their spending on AI as a % of total capex\n",
      "\n",
      "It is also rumored that NVIDIA is to ship 1.5M and 2M H100s in 2024, up from the 500,000 expected this year.\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Tesla marches towards a Top-5 largest compute cluster for AI in the world\n",
      "\n",
      "In our Compute Index from 2022, Tesla ranked 4th based on its A100 GPU count. As of summer 2023, the \n",
      "company brought online a new 10,000 H100 cluster, already making it one of the largest online to date. \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Meta announced MTIA, the company’s ﬁrst in-house accelerator based on open source RISC-V architecture that \n",
      "addresses the requirements of deep learning-based recommendation models. This is driven by growing size \n",
      "and complexity of models deployed in production and the slow inference speeds offered by GPUs. \n",
      "\n",
      "More hyperscalers develop their own inference hardware for internal AI workﬂoads\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "NVIDIA, Intel and AMD make Chinese-export controls proof chips\n",
      "According to NVIDIA’s CFO, China historically accounted for 20-25% of NVIDIA’s revenue from data \n",
      "centre-related products (Financial Times). As a result, as the US commerce department became increasingly \n",
      "aggressive with export controls of AI chips, NVIDIA (and its competitors) developed chips which ﬂy right below \n",
      "the export list thresholds.\n",
      "\n",
      "● In late August 2022, NVIDIA’s A100 and H100 – their most powerful chips \n",
      "for AI applications – were added to the US Commerce Department’s export \n",
      "control list and became out of reach for Chinese companies. By November, \n",
      "NVIDIA had already started advertising the A800 and H800 chips, which it \n",
      "designed to be below the performance threshold set by the US ban.\n",
      "● Intel did the same with a new version of their Habana Gaudi 2 chip, and \n",
      "AMD expressed a similar intent.\n",
      "● As a result, the likes of ByteDance and Baidu have ordered >$1B worth of \n",
      "A800/H800 NVIDIA GPUs. There has also been reports of increasing \n",
      "A100/H100 GPU trafﬁc in China, but on a much smaller scale.\n",
      "● Arm, whose IP underpins the chips in 99% of the world’s smartphones, is working to reposition itself as a \n",
      "player in the AI market. It has partnered with self-driving car company Cruise and NVIDIA on its Grace \n",
      "Hopper chip (where its tech acts in a supporting role).\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Softbank re-lists Arm on the NASDAQ after its sale to NVIDIA was blocked\n",
      "Back in 2020, we predicted that NVIDIA would fail to complete its acquisition of Arm. In September, Arm was \n",
      "relisted on the Nasdaq, achieving a valuation of $60 billion at open.\n",
      "\n",
      "● However, it won’t be plain-sailing. Revenue was ﬂat over the last \n",
      "ﬁscal year and 25% comes from Arm China, an independent \n",
      "subsidiary required for sales into the Chinese market.\n",
      "● Arm may have the potential to raise its low royalty rates per \n",
      "device, considering its huge market share, but will need to balance \n",
      "this with growing open source alternative architectures like \n",
      "RISC-V. \n",
      "● As Arm does not sell physical chips, it has managed to swerve the \n",
      "impact of sanctions so far, but as the US-China chip wars escalate, \n",
      "there is no guarantee this will last.\n",
      "● ElevenLabs now had over 2M registered users and is \n",
      "growing fast. It took half the time to to get the second \n",
      "million of users than the ﬁrst. Users cumulatively uploaded \n",
      "over 10 years of audio content. Initially geared towards \n",
      "creators and publishers, ElevenLabs is now adapting to a \n",
      "large range of use-cases from AI agents, companion, \n",
      "entertainment, and gaming.\n",
      "● Uizard, a product design company powered by AI tools, said \n",
      "it recorded $3.2M ARR up to July ’23, which is 13x YoY. The \n",
      "company had crossed $1M ARR in April, and went from \n",
      "$1M to $3M in 3 months.\n",
      " In 2022, we predicted: “Generative audio tools emerge that attract over 100,000 developers by September \n",
      "2023.” Both ElevenLabs (UK) and Resemble AI (US) exceeded that threshold. Another domain, product design, is \n",
      "seeing rapid integration of generative AI technology, to the beneﬁt of fast-moving companies like Uizard.\n",
      "\n",
      "2022 Prediction: Generative AI applications grow in popularity\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Video too is a rapidly advancing frontier for GenAI. Founded in 2017, London-based Synthesia launched their \n",
      "AI-ﬁrst video creator in 2020. The system generates multi-lingual avatars that enact a script for use by \n",
      "consumers and enterprises alike. Once considered to be “fringe”, Synthesia is now used by 44% of the Fortune \n",
      "100 for learning and development, marketing, sales enablement, information security and customer service. \n",
      "Over 9.6M videos have been generated with the service since launch in 2020. \n",
      "\n",
      "2022 Prediction: Generative AI applications grow in popularity\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "2020 data starts on 1 May. 2023 data stops on 1 Sept.\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "OpenAI’s ChatGPT is one of the fastest growing internet products\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "OpenAI is now printing real money at scale…but at what cost?\n",
      "Only 12 months, the revenue projections made by OpenAI in the lead up to its $10B fundraise were met with \n",
      "much scepticism. Today, the company is ripping past its targets. How long will this last? And at what cost?\n",
      "��\n",
      "��\n",
      "Chegg, an NYSE-listed company focused on improving learning and learning outcomes for students, was hit \n",
      "hard by the launch of ChatGPT. In May 2023, the company said “In the ﬁrst part of the year, we saw no noticeable \n",
      "impact from ChatGPT on our new account growth and we were meeting expectations on new sign-ups.” Students \n",
      "that paid Chegg to practice exams and get homework feedback turned to ChatGPT instead. As a result, their \n",
      "share price plummeted >40%. In Chegg’s August 2023 earnings call, the company said “We’ve pivoted the \n",
      "company to harness AI to better serve learners.” They’re building internal LLMs in partnership with Scale AI. \n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Feeling the ChatGPT heat: education gets hit ﬁrst and Chegg is ﬁghting back\n",
      "Stack Overﬂow, a (pre-AI) de facto source for developer’s to ﬁnd solutions to their coding problems, placed a \n",
      "ban on responses generated by ChatGPT and has suffered trafﬁc losses as a result of ChatGPT’s popularity. \n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Feeling the ChatGPT heat: coding is next…and developers are loving it!\n",
      "Left ﬁgure credit: Andre Retterath\n",
      "If it's meant to be, it will be (no matter how long it takes). GitHub has ﬁnally launched their coding assistant, \n",
      "CoPilot, to hugely positive reception. The system is trained on billions of lines of code. \n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Results are in: GitHub CoPilot drives signiﬁcant productivity gains for developers\n",
      "● In Sept 2022, GitHub ran an experiment with 95 professional \n",
      "developers, split them randomly into two groups, and timed \n",
      "how long it took them to write an HTTP server in JavaScript. \n",
      "This found signiﬁcant productivity gains. \n",
      "● In June 2023, GitHub reported data from 934,533 CoPilot \n",
      "users. Interestingly, productivity dips a little bit before \n",
      "signiﬁcantly increasing as Copilot users get acquainted with \n",
      "the tool, and the less experienced users are the ones who \n",
      "beneﬁt the most (~32% productivity gain).\n",
      "A new MIT study supports popular wisdom: ChatGPT helps with writing. Speciﬁcally, for “mid-level professional \n",
      "writing” the study showed that, compared to a control group, workers using ChatGPT took 40% less time to \n",
      "complete their task, and the output quality was measured to be 18% better.\n",
      "\n",
      "\n",
      "ChatGPT drives productivity in (repetitive, boring?) writing\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Certain less obvious GenAI use cases have also gained signiﬁcant traction\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "We’ve seen huge consumer interest in users to interact with customised chatbots. A16z-backed Character.AI \n",
      "raised a $150M Series A and reported 200M monthly visits to its site ahead of the launch of its app. Many of \n",
      "their uses are benign - for example, their use as grammar tools or in fanﬁction communities, but we’ve seen \n",
      "commercial and ethical challenges. We’ve seen reports of users developing emotional dependencies on their \n",
      "bots, companies struggle with the trade-off between the popularity of explicit content and its implication for \n",
      "their brand, as well as claims of extremist content.\n",
      "After a breakout year in 2022 with the release of Stable Diffusion, Midjourney and Stability are still racing \n",
      "ahead with continuous improvements to their models. Though seemingly slower to react on the text-to-image \n",
      "front, OpenAI has released its best text-to-image model yet, DALL-E 3. And there are still new entrants like \n",
      "Ideogram, whose founders are the creators of Google’s Imagen – their model notably can spell. Meanwhile \n",
      "we’ve seen countless integrations of text-to-image models in popular products, most notably on Adobe’s \n",
      "Fireﬂy, Photoroom, or even Discord.\n",
      "\n",
      "Text-to-image models: Competition intensiﬁes and integrations abound\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Midjourney’s revenue, which had already reached $1M MRR in March \n",
      "2022, is projected to reach $200M ARR in 2023. Its number of users grew \n",
      "from 2M to 14.8M YoY. Notably, Midjourney is integrated in Discord, where \n",
      "users can generate images on a Discord server. According to Discord, \n",
      "more than 30 million people use AI apps on its servers every month, \n",
      "creating more than 1 billion unique images.\n",
      "● Photoroom, a French startup specializing in photo editing, said that with \n",
      "the introduction of generative AI in February, the company doubled its \n",
      "revenue and number of users over the last 6 months.\n",
      "Stability’s SDXL\n",
      "OpenAI’s DALL-E 3\n",
      "Midjourney v5.2\n",
      "Ideogram v0.1\n",
      "But GenAI’s wow effect is (so far) insufﬁcient for users to stick around…\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Compared to the most popular incumbent apps such as YouTube, Instagram, TikTok or WhatsApp, GenAI apps \n",
      "such as ChatGPT, Runway or Character.ai suffer from lower median retention and daily active users.\n",
      "Figure credit: Sequoia Capital\n",
      "In Oct 2022, Shutterstock - a leading stock multimedia provider - announced it will work with OpenAI to bring \n",
      "DALL·E-powered content onto the platform. Then in July 2023, the two companies signed a 6-year content \n",
      "licensing agreement that would give OpenAI access to Shutterstock's image, video and music libraries and \n",
      "associated metadata for model training. Furthermore, Shutterstock will offer its customers indemniﬁcation for AI \n",
      "image creation. The company also entered into a content license with Meta for GenAI. This pro-GenAI stance is in \n",
      "stark contrast to Shutterstock’s competitor, Getty Images, which is profoundly against GenAI as evidenced by its \n",
      "ongoing lawsuit against Stability AI for copyright infringement ﬁled in Feb 2023. \n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "2022 Prediction: A major user generated content site negotiates a commercial \n",
      "settlement with a start-up producing AI models (e.g. OpenAI) for training on their corpus\n",
      "vs.\n",
      "In July 2023, OpenAI and the Associated Press (AP) entered into a licensing agreement for partial access to AP’s \n",
      "news stories dating back to 1985. Meanwhile, AP will gain access to OpenAI technology and product expertise to \n",
      "explore generative applications. Although AP doesn’t have LLM-based applications in production, it has made \n",
      "use of AI systems to create automated corporate earnings and sporting event recaps. \n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "2022 Prediction: A major user generated content site negotiates a commercial \n",
      "settlement with a start-up producing AI models (e.g. OpenAI) for training on their corpus\n",
      "A US District Court has reafﬁrmed the long-standing principle that human authorship is needed for copyright \n",
      "protection. While appeals are likely, important precedent may now have been set.\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "US Courts set precedent for AI-generated content being unsuitable for copyright \n",
      "protection, but then another on fair use\n",
      "● The US District Fort for the District of Columbia rejected a claim from Stephen Thaler that the 2012 image “A \n",
      "Recent Entrance to Paradise” (on the right) was worthy of copyright protection.\n",
      "● The Copyright Ofﬁce, however, has established an initiative to examine the \n",
      "impact of AI on copyright law and has released new copyright guidance, \n",
      "covering literary, visual, audiovisual, and sound. It stipulates that any \n",
      "artwork needed a human author and that applications needed to specify \n",
      "where AI was used.\n",
      "● More challengingly for providers, in May 2023 ruling in a copyright case \n",
      "over a 1981 portrait of Prince, the US Supreme Court applied a new, \n",
      "stricter interpretation of what constitutes as ‘transformative’ under fair \n",
      "use. This could well make the scraping of books and artwork for models’ \n",
      "training data legally riskier.\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● In the UK and US, Getty Images is suing Stability, arguing that Stability had copied millions of photographs \n",
      "from its collection, altered or removed copyright information, and accused Stable Diffusion of generated \n",
      "images that bear a modiﬁed version of the Getty Images watermark.\n",
      "● OpenAI and Meta are facing lawsuits claiming that ChatGPT and LLaMa on the grounds that they did not \n",
      "consent to their copyrighted books being used in training datasets. The New York Times is said to be mulling a \n",
      "similar suit against OpenAI. Three artists are suing Stability, DeviantArt and Midjourney for using their artwork \n",
      "to train an image generator that creates “infringing derivative works”.\n",
      "● The UK has a text and data mining exception to copyright law, but this only extends to non-commercial use; \n",
      "plans to widen this exemption have been shelved. The EU had a similar exemption, but the AI Act states that \n",
      "foundation model providers will have to provide summaries of copyrighted material used to train their models \n",
      "(which could prove technically challenging)\n",
      "● Microsoft has moved to reassure users of their Copilot tools that the corporation will assume any legal risks in \n",
      "the event of any copyright claims.\n",
      " Cases featuring the major text and image generation are being fought in the UK and US. While the companies \n",
      "contend that they are engaging in fair use or freedom of expression, there are signs that trouble may lie ahead.\n",
      "But cases continue to be fought in multiple jurisdictions about copyright infringement\n",
      "From labels to preferences\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      " As instruction ﬁne-tuning and RLHF became the default method to ﬁne-tune and align language models, \n",
      "companies offering labeling services like Scale AI and Surge HQ stand to register exceptional growth from the \n",
      "exploding popularity of LLMs. Both companies bolster an impressive list of customers, from AI startups to large \n",
      "corporate clients to leading labs in LLM research. Scale AI was last valued at $7.3B back in 2021, pre-Stable \n",
      "Diffusion and the ChatGPT frenzy.\n",
      "Open source AI is on a tear at a time when incumbents push for closed source AI\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      " Hugging Face, the now 7-year old company that has ﬁrmly become the town hall for open source AI, is seeing \n",
      "signiﬁcant momentum as the community vies to keep AI models and datasets accessible to all. Over 1,300 \n",
      "models have been submitted to their Open LLM Leaderboard in a few months and >600 million model \n",
      "downloads in August 2023 alone. These models are exposed on Spaces as web applications built with tools such \n",
      "as Gradio or Streamlit, enabling broader accessibility and rapid prototyping. Monthly active Gradio users has \n",
      "grown 5x from 120k (Jan ‘23) to 580k (Aug ‘23).\n",
      "●\n",
      "Prior to the acquisition, Mosaic showed impressive engineering feats like training Stable Diffusion from \n",
      "scratch for <$50k (8x reduction from the original) and building sota LLMs with long context length.\n",
      "●\n",
      "The deal marked a major moment in the short history of generative AI frenzy. \n",
      "●\n",
      "Snowﬂake had a similar strategy: together with Azure, it provide customers with access to OpenAI’s models.\n",
      "\n",
      "\n",
      "Monolithic LLMs or specialised application-dependent LLMs?\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Databricks acquired MosaicML for $1.3B in order to help companies build (most likely ﬁnetune) their own LLMs. \n",
      "Rather than a single monolithic model that knows everything, the future could belong to a set of specialised \n",
      "models trained on enterprise data or for speciﬁc tasks.\n",
      "mRNA vaccine leader, BioNTech acquired AI company InstaDeep for €500M, while Sanoﬁ goes “all in” on AI, \n",
      "Merck enters into new deals with AI-ﬁrst drug company, Exscientia, worth up to $674M and AstraZeneca \n",
      "partners with Verge Genomics in a deal worth up to $840M.\n",
      "\n",
      "Once ignored by major pharma companies, AI is moving front and center for some\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "NVIDIA continues its share price performance tear and blesses its partners too\n",
      "\n",
      "On the day of NVIDIA’s $50M investment announcement into Recursion Pharmaceuticals, the latter’s share price \n",
      "surged 80% to create an additional $1B of market value. Such a reaction demonstrates the AI fever. \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "DeepMind to Google DeepMind back to DeepMind and now to Google DeepMind…v2!\n",
      "2010\n",
      "2014\n",
      "2015\n",
      "2023\n",
      "The pioneering AI company, DeepMind, is now at the forefront of Google’s counteroffensive in generative AI \n",
      "following its merger with Google Brain.\n",
      "DeepSpeech 2: The early masters of scale\n",
      "\n",
      "In 2015, Baidu’s Silicon Valley AI Lab introduced a fully end-to-end deep learning based system for speech \n",
      "recognition. The work did away with hand-crafted feature-based pipelines and heavy use of computation: “Key \n",
      "to our approach is our application of HPC techniques, resulting in a 7x speedup over our previous system [...] Our \n",
      "system is competitive with the transcription of human workers when benchmarked on standard datasets.” A 2017 \n",
      "paper from the same lab, “Deep learning scaling is predictable, empirically” demonstrated early evidence for \n",
      "“scaling laws”, which now underpins the large-scale AI we see and use today. Many DS2 authors have gone onto \n",
      "be founders or execs of leading ML companies, often leading their large scale efforts in language modeling and \n",
      "related ﬁelds.\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "All but one authors of the landmark paper that introduced transformer-based neural networks have left \n",
      "Google to build their own startups. The Transformers Maﬁa have collectively raised \n",
      "Attention is all you need… to build raise billions for your AI startup\n",
      "Capital raised in 2023 alone\n",
      "$150M \n",
      "$100M\n",
      "$270M\n",
      "$10.3B\n",
      "ex-\n",
      "ex-\n",
      "$350M\n",
      "GAIA-1 is a 9-billion parameter generative world model developed by Wayve for autonomous driving. It \n",
      "leverages video, text and action inputs to generate realistic driving scenarios and offers ﬁne-grained control \n",
      "over ego-vehicle behaviour and scene features. It shows impressive generalisation abilities to ego-agent \n",
      "behaviours that are outside of the training set and controllability of the environment through text, making it a \n",
      "powerful neural simulator useful for training and validating autonomous driving models.\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Autonomous driving meets GenAI\n",
      "● This is a major moment for autonomous driving. Approval from \n",
      "the California Public Utilities Commission was the last in a \n",
      "series of approvals that took years to obtain. Waymo’s CEO \n",
      "Tekendra Mawakana stated that the permit “marks the true \n",
      "beginning of our commercial operations in San Francisco”. \n",
      "● However the jury is still out on the economics of a driverless \n",
      "taxi service versus trucking and logistics. Waymo paused their \n",
      "autonomous trucking service at the end of July, while others \n",
      "(Aurora for instance) are prioritizing it over robotaxis.\n",
      "● Former Argo AI leaders founded Stack AV, an autonomous \n",
      "trucking startup which raised $1B Series A from Softbank.\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Autonomous rides are now commercial (in California)\n",
      "Waymo and Cruise have been granted permission to launch paid 24/7 autonomous driving services in San \n",
      "Francisco. Previously paid rides were only possible when a driver was in the vehicle for monitoring.\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "“GenAI” is the new “new” thing: AI investments are stable vs. 2022, powered by GenAI\n",
      "Funding for startups using AI H1 2023 was nearly on par with H1 2022…without capital pouring into GenAI, \n",
      "overall AI investments would have suffered a 40% drop compared to last year vs. 54% drop across all startups.\n",
      "Data as of 29 Sept 2023\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "Trillions of value: The combined enterprise value of private and public companies using AI\n",
      "Public valuations dropped by ⅓ after 2021, but are on their way to recovering, while private market valuations \n",
      "remain stable and are yet to see a haircut. Notably, 50% of the S&P 500 gains in 2023 were driven by “The \n",
      "Magniﬁcent Seven”: Apple, Microsoft, NVIDIA, Alphabet, Meta, Tesla and Amazon as key drivers and beneﬁciaries \n",
      "of AI acceleration. \n",
      "Data as of 29 Sept 2023\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "US AI companies absorb 70% of global private capital in 2023, up from 55% in 2022\n",
      "Funding to private US and UK AI companies is steady YoY, while capital for European AI companies drops >70%.\n",
      "Data as of 29 Sept 2023\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "The US continues to lead by number of AI unicorns, followed by China and the UK\n",
      "The from 2022 continues: the US grows its unicorn count to 315 from 292 and total enterprise value to $5.9T \n",
      "from $4.6T. The UK adds 3 more unicorns but sees cumulative enterprise value regress to $155B from $207B.\n",
      "Data as of 19 Sept 2023\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "Enterprise software, ﬁntech and healthcare are the most invested AI categories globally\n",
      "Data as of 14 Sept 2023\n",
      "$ invested in AI categories \n",
      "2010-23\n",
      "Deal volume in AI categories\n",
      "2022-23\n",
      "% of deals for AI startups \n",
      "Deal volume in AI categories\n",
      "2022-23\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "Although IPOs dried up in 2023, the M&A market continues to stay strong\n",
      "Not much public market activity outside of a few SPACs (e.g. Arrival, Roadzen, Triller) vs. 98 in 2022. However, \n",
      "there were several large acquisitions MosaicML + Databricks ($1.3B), Casetext + Thomson Reuters ($650M), and \n",
      "InstaDeep + BioNTech (€500M).\n",
      "Data as of 19 Sept 2023\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "24% of all corporate VC investments went into AI companies in 2023\n",
      "In 2023, corporates refocused their investments towards GenAI. They cut investments into non-AI companies by \n",
      "50% YoY while keeping AI investments roughly steady ($29B in ‘22 vs. $22B in ‘23).\n",
      "Data as of 19 Sept 2023\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "2023 sees a massive acceleration in GenAI funding\n",
      "Named after a textbook genre of artiﬁcial intelligence, GenAI companies are attracting mountains of capital.\n",
      "Data as of 2 Oct 2023\n",
      "$950M (2010-18 combined)\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "Check out those GenAI round (GPU bills) sizes: $18B invested in 2023 alone!\n",
      "Mega rounds capture the headlines and are driven by “foundation” or “frontier” model companies selling equity \n",
      "dollars to purchase cloud computing capacity to train large-scale systems. This trend might ﬁnally see a break: \n",
      "CoreWeave raised a $2.3B debt facility (instead of equity) to buy its GPUs.\n",
      "Data as of 2 Oct 2023\n",
      "Instead of one such relationship, NVIDIA pursues a multi-pronged land-grab on AI, which includes a) \n",
      "investments into private and public AI-ﬁrst companies, b) arming specialized GPU cloud providers, and c) \n",
      "adding new industry verticals.\n",
      "\n",
      "XXX\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "2022 Prediction: NVIDIA forms a strategic relationship with an AGI organization\n",
      "Select investments\n",
      "GPU cloud providers\n",
      "Industry verticals\n",
      "Recursion (drug discovery)\n",
      "Synthesia (video generation)\n",
      "Cohere (LLMs)\n",
      "Adept (process automation)\n",
      "CoreWeave\n",
      "Lambda\n",
      "BioNeMo: GenAI cloud \n",
      "service in drug discovery.\n",
      "Picasso: GenAI cloud \n",
      "service for visual design.\n",
      "Omniverse: digital twins of \n",
      "the world.\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "A handful of corporates were at the center of some of the highest proﬁle AI fundraises\n",
      "Monster round\n",
      "up to $4B\n",
      "Mega round \n",
      "$1.3B\n",
      "Series C\n",
      "$141M\n",
      "Series C\n",
      "$270M\n",
      "Series D\n",
      "$235M\n",
      "Beast round \n",
      "$10B\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "GenAI companies raised 33% larger Seeds and 130% larger As than all startups in 2023\n",
      "Compute and talent isn’t coming cheap when the world’s attention is on you.\n",
      "Data as of 19 Sept 2023\n",
      "Section 3: Politics\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "After years of speculation about mounting potential divergence in regulatory approaches, we’re starting to see \n",
      "regulatory approaches stabilise and settle into a handful of distinct approaches.\n",
      "Have we reached “peak” regulatory divergence?\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Relying on existing laws \n",
      "and regulations\n",
      "Introducing AI-speciﬁc \n",
      "legislative frameworks\n",
      "Banning speciﬁc services \n",
      "(e.g. ChatGPT)\n",
      "Represented by the UK and India, this approach operates on the basis that AI does not currently require any \n",
      "additional legislation. \n",
      "“Light-touch” or “pro-innovation”: scepticism of large-scale regulation\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● So far, both the UK and India have stressed the economic and social upside of AI, with the March 2023 white \n",
      "paper and a parliamentary response from India’s digital minister arguing that any current risks could be absorbed \n",
      "by current sectoral regulations and privacy legislation.\n",
      "● The UK did, however, include some AI principles (grounded in similar work from the OECD) for regulators to \n",
      "follow and invested an initial £100M in a taskforce focused on frontier model safety, led by SOAI co-author Ian \n",
      "Hogarth. The team appears to be a world-ﬁrst, in attempting to built a dedicated unit drawing on industry and \n",
      "academia to assess risk at the frontier,\n",
      "● The UK also secured a special agreement with Google DeepMind, Anthropic, and OpenAI to gain early access to \n",
      "their most advanced frontier models to improve their understanding of risk.\n",
      "● While popular with industry, it is unclear if these approaches will survive. Recently the UK Government dropped \n",
      "“light-touch” from its vocabulary and has repositioned itself as the home of the AI safety debate.\n",
      "● The Indian Ministry of Electronics and Information Technology has now said forthcoming legislation may indeed \n",
      "cover some forms of AI harms, alongside web3 and other technology.\n",
      "The EU and China are leading the pack in passing new, AI-speciﬁc legislation, with especially stringent measures \n",
      "around foundation models\n",
      "Wide-ranging legislation\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The EU’s AI Act is entering its closing legislative stages in the coming months. The Parliament’s current draft has \n",
      "added regulations around foundation models and general purpose AI systems (which are stipulated separately). \n",
      "● While the rest of the AI Act tiers requirements based on how ‘high risk’ a system’s intended use is, in the \n",
      "Parliament’s draft, all commercial foundation model providers are subject to special requirements.\n",
      "● These include risk assessments, disclosing when content is generated AI, prevention of a model from generating \n",
      "illegal content, and publishing summaries of any copyrighted data used for training.\n",
      "● Meanwhile, China brought in speciﬁc legislation on recommender systems, alongside generative AI regulations. \n",
      "This updated previous ‘deep synthesis’ regulation that required AI-generated content to be labelled, protections \n",
      "against misuse, barred anonymous accounts using services, and included censorship requirements. Developers \n",
      "will also have to register their algorithms with the government and there is a special “security assessment” for \n",
      "any deemed capable of inﬂuencing public opinion.\n",
      "● China is expected to follow this up with a national AI law later this year - but details have not yet been released.\n",
      "In other markets, we’re either seeing slimmed down national regulation or a preponderance of local laws. While \n",
      "avoiding some of the challenges of major legislation, they also risk pleasing no one.\n",
      "Hybrid models: The best or worst of both worlds?\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The US is unlikely to pass a federal AI law anytime soon and in some respects is pursuing a UK-style approach, \n",
      "with an emphasis on voluntary commitments (e.g. the July White House agreement) and research to establish \n",
      "what constitutes good practice (e.g. the National Institute of Standards and Technology's AI Risk Management \n",
      "Framework). Some of these commitments, for example, involve third party evaluations, but do not specify which \n",
      "third party this would be and the company could theoretically ignore their ﬁndings.\n",
      "● However, individual US states have been moving to introduce AI laws that vary in strictness. We have mandatory \n",
      "transparency laws around “proﬁling” and automated decisions in California, Colorado, Texas, Virginia and others. \n",
      "Meanwhile, New York and Illinois have speciﬁc laws around the use of AI in hiring decisions. \n",
      "● Canada is attempting a slimmed down version of the EU AI Act, banning certain and applications and regulating \n",
      "others. Instead of an EU-style sliding scale of obligations, Canada’s Artiﬁcial Intelligence and Data Act only \n",
      "regulates “high-risk” applications. Enforcement will fall to an existing department, rather than a new regulator.\n",
      "● This approach, however, has been attacked from both sides - with critics accusing it of both going too far or not \n",
      "far enough.\n",
      "Various global regulators have been ﬂoated as models, including the International Atomic Energy Agency, the \n",
      "Intergovernmental Panel on Climate Change, and CERN. These proposals, however, remain conﬁned to academic \n",
      "papers for the moment.\n",
      "State action on global governance is in its early stages…\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The EU and US have announced that they are working on a joint \n",
      "AI code of conduct, which will include non-binding international \n",
      "standards on risk audits and transparency, among other \n",
      "requirements.\n",
      "● The G7 will create the ‘Hiroshima AI process’, in collaboration with \n",
      "the OECD and Global Partnership on AI, which will set a \n",
      "“collective approach” to generative AI governance. \n",
      "● We’ve also seen the ﬁrst steps from the UN, which opened a \n",
      "consultation in August to inform recommendations on \n",
      "governance a ahead of a 2024 ‘Summit of the Future’ hosted by \n",
      "the Ofﬁce of the Secretary-General’s Envoy on Technology.\n",
      "● The UK is planning to host a summit themed around safety and governance in November 2023, involving \n",
      "major democracies and China, as it attempts to position itself as the world’s leading safety research hub.\n",
      "As governments struggle to form deep, shared positions on governance issues, the developers of frontier models \n",
      "are making a push to shape norms.\n",
      "…as a result, the largest labs are trying to ﬁll the vacuum \n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "●\n",
      "Anthropic, Google, OpenAI, and Microsoft launched the Frontier Model \n",
      "Forum - a body designed to promote the responsible development of frontier \n",
      "models and to share knowledge with policymakers.\n",
      "●\n",
      "Over May-June 2023, Sam Altman, CEO of OpenAI went on a ‘world tour’ \n",
      "meeting policymakers and regulators in key markets. Altman’s proposals \n",
      "included licencing regimes for powerful models and the introduction of \n",
      "independent audit requirements.\n",
      "●\n",
      "Labs have also been producing their own policy proposals. OpenAI have \n",
      "argued that we will eventually need an IAEA for AI to audit and enforce \n",
      "safety standards; while Anthropic have outlined its ‘portfolio’ approach to \n",
      "governance, combining legislation, independent auditing, and robust internal \n",
      "controls. The most far-reaching has come for Mustafa Suleyman of \n",
      "Inﬂection, who with Ian Bremmer of the Eurasia Group, outlined a three-tier \n",
      "global governance structure.\n",
      "Late last year, the US introduced its toughest export control regime towards China in recent decades, barring the \n",
      "sale of advanced chips or the tools made to use them to Chinese ﬁrms. This abandoned a previous policy of \n",
      "attempting to slow Chinese technological process in favour of actively trying to degrade Chinese capabilities. \n",
      "The US successfully enlists its allies in the chip wars…\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Japan toughened its export limits to include the equipment \n",
      "make less-advanced chips. The Netherlands has widened its \n",
      "restrictions on the export of the deep ultraviolet lithography \n",
      "machines. Their ﬁne components make them hard to replicate \n",
      "and there are few in circulation to smuggle.\n",
      "● Germany has joined the US in reshoring efforts by handing €15B \n",
      "in subsidies to Intel and a TSMC-led consortium to build \n",
      "semiconductor plants in the US.\n",
      "● There are lingering doubts about the effectiveness of this \n",
      "approach. Critics are questioning how realistic the EU drive for \n",
      "self-sufﬁciency is, considering their lack of control over the \n",
      "market for semiconductor raw materials.\n",
      "In last year’s report, we asked if US restrictions would lead to advances in Chinese R&D. The billions of dollars in \n",
      "domestic subsidy have so far been hit and miss, so the government is going on the attack.\n",
      "… and the Chinese response remains scrambled\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● In May 2023, China responded by barring infrastructure providers from using chips made by US company Micron \n",
      "- a relatively small player in the Chinese market. However, they have since introduced a licencing regime on the \n",
      "export of gallium and germanium, which are earth metals used to make top of the range semiconductors, \n",
      "alongside components in solar panels and electric vehicles.\n",
      "● In August, China blocked Intel’s planned $5.4B acquisition of Tower Semiconductor, which would have given Intel \n",
      "some of the foundry capacity it needed to fuel its ambitions of challenging TSMC and Samsung as a supplier of \n",
      "chips to third parties. \n",
      "● Perhaps as a tacit acknowledgement that these approaches aren’t working, China recently ﬂoated the idea of \n",
      "tying semiconductor access to progress on climate pledges. The US immediately rejected this.\n",
      "● Such escalating rivalry carries risks for both sides. By restricting access to the China, as NVIDIA CEO Jensen \n",
      "Huang has warned, the US risks weakening the market for its own manufacturers (undercutting an objective of \n",
      "the CHIPS Act), while China can only push metal restrictions so far before it damages its own exporters.\n",
      "Amid tightening restrictions, Huawei surprised the world with its new Mate 60 Pro phone, power by the advanced \n",
      "Kirin 9000S chip, produced by Chinese chipmaker SMIC.\n",
      "However, does Huawei’s new chip signal a breakthrough moment?\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● While some commentators have suggested that this is a sign that US \n",
      "and Dutch sanctions are failing to have the anticipated effect, there \n",
      "are reasons to avoid jumping to conclusions.\n",
      "● 7nm is no longer state of the art and this advance still leaves SMIC \n",
      "lagging the likes of TSMC by half a decade. It is not necessarily \n",
      "surprising that SMIC was able to make them using the DUV machines \n",
      "they already owned. With access to more advanced lithography \n",
      "machines cut off, it may be harder for them to achieve 5nm.\n",
      "● The US has also questioned China’s ability to manufacture the chip at \n",
      "scale. It could well be that the Chinese government’s days of mass \n",
      "semiconductor subsidy are far from over.\n",
      "● SMIC succeeded in replicating a manufacturing process called 7 nanometer, producing the most advanced \n",
      "semiconductor we have yet seen from a Chinese company.\n",
      "Currently, the EU and the US are superﬁcially well-placed, but Leonardo and Perlmutter, their national HPC \n",
      "clusters, are not dedicated to AI and resources are shared with other areas of research. Meanwhile, the UK \n",
      "currently has fewer than 1,000 NVIDIA A100 GPUs in public clouds available to researchers.\n",
      "Governments are building out compute capacity, but are lagging private sector efforts \n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The UK’s compute review recommended building out a cluster of 3,000 GPUs that academics and commercial \n",
      "users could access and set a deadline of 2026 for bringing exascale capability online.\n",
      "● The US has plans to build out National AI Research Resource that would make 140-180 million hours on \n",
      "quad-GPU nodes available to researchers. It’s currently waiting on Congress to authorise the required $2.6B \n",
      "investment over six years.\n",
      "● However, both governments have faced calls to go further. Anthropic suggested that the US should invest $4B in \n",
      "creating a 100,000 GPU cluster, while the Tony Blair Institute has pushed for the UK to create a 30,000 GPU \n",
      "cluster.\n",
      "● In the meantime, private companies are rushing to buy every GPU they can ﬁnd. Baidu, ByteDance, Tencent, \n",
      "Alibaba have already spent $9B on NVIDIA orders for delivery over the course of 2023/2024.\n",
      "US and European militaries have been trying to diversify beyond the primes to ensure they don’t miss out on the \n",
      "latest advances in capabilities, but the number of winners remains small.\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "AI and defense tech attracts record funding…but is politics stalling progress? \n",
      "● Funding for US defense startups hit $2.4B last year, more than 100x the European total, but the number of \n",
      "companies able to win consistent, sustained work remains small. A coalition of US VCs and tech companies are \n",
      "calling for a reform to “antiquated methods for developing requirements and selecting technologies”.\n",
      "● Anduril’s Series E is greater than all British defense tech \n",
      "investment between 2013-2022 combined, while Helsing’s €209M \n",
      "Series B is the only signiﬁcant fundraise on the continent. \n",
      "European LPs largely aren’t reversing their aversion to defense \n",
      "investment, meaning that supranational institutions are stepping \n",
      "in to ﬁll the gap.\n",
      "● Alongside the new €1B NATO Innovation Fund, the European \n",
      "Investment Fund is thought to have allocated €200M to defense \n",
      "investment. Will these funds make big bets, or go cautious and \n",
      "create a European ‘valley of death’?\n",
      "Ukraine is providing an early glimpse of the future of war, combining intensive, often cheap, drone use with \n",
      "advanced satellites and situational awareness systems. Drones are the most high-proﬁle example, whether it’s \n",
      "the Punisher drone from UA Dynamics, the Turkish Bayraktar TB2, or cheap home-made alternatives. These cost a \n",
      "fraction of the US Reaper and Predator drones that have price tags of $30-50M.\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Meanwhile, Ukraine acts as a lab for AI warfare\n",
      "● Ukraine’s Zvook project detects the sound signature of Russian \n",
      "missiles. Originally trained on video footage of Russian missiles, \n",
      "the system is supported by a network of acoustic monitoring \n",
      "devices across the country.\n",
      "● After successful trials in 2022, the Ukrainian Armed Forces fully \n",
      "authorised the use of Delta in February. Delta is a cloud-based \n",
      "situational awareness system that integrates data in real-time \n",
      "from different sensors, satellites and drones, along with \n",
      "intelligence or images taken from those on the ground. \n",
      "● The system is highly decentralised and avoids using either \n",
      "vulnerable mobile networks or ﬁbre optic cables by using Starlink.\n",
      "Use of AI-based manipulation in elections has been mounting and there are concerns ahead of the 2024 US \n",
      "presidential election, following signiﬁcant technological progress. \n",
      "Have we entered the AI era in elections?\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The US Federal Election Commission is seeking public comment on \n",
      "whether new regulations are needed for AI in political advertising.\n",
      "● The big labs’ voluntary White House commitments include ensuring \n",
      "users are aware when content is AI-generated (e.g. through \n",
      "watermarking). Google has announced that any AI-generated election \n",
      "ads on their platform will need a disclaimer.\n",
      "● Some US states already restrict AI-generated videos, but there are \n",
      "concerns that the ease with which users can anonymously access tools \n",
      "means the legislation is not enforceable.\n",
      "● We’ve seen a growing use of political AI-generated images and video content including in a Canadian local \n",
      "election, the Russia-Ukraine war, the Slovakian parliamentary election, the Turkish presidential election, and \n",
      "a Chinese disinformation campaign. So far, we’re yet to see clear-cut evidence that these crude efforts have \n",
      "been more successful than traditional disinformation campaigns.\n",
      "Are the ‘culture wars’ coming to AI?\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● In response, OpenAI released a blogpost detailing its moderation \n",
      "methodology, and Sam Altman has suggested that in future, people may \n",
      "be able to ﬁnetune ChatGPT iterations beyond some ‘very broad absolute \n",
      "rules’ to remove OpenAI from some of these values questions.\n",
      "● Following long-standing complaints about OpenAI’s “political correctness”, \n",
      "Musk launched xAI, a startup focused on trying “to understand the true \n",
      "nature of the universe”. In a Twitter Spaces following the launch, Musk \n",
      "emphasised that “our AI can give answers that people may ﬁnd controversial \n",
      "even though they are actually true”. Little is yet known about xAI’s work.\n",
      "● In August, political science journal Public Choice, published a study ﬁnding \n",
      "ChatGPT displayed “strong and systematic political bias … which is clearly \n",
      "inclined to the left”, which in turn attracted a series of critical responses.\n",
      " ChatGPT has become a ﬂashpoint in a series of heated cultural debates, largely in the US, with particularly \n",
      "conservatives sharing screenshots to allege bias in ChatGPT’s training and ﬁne-tuning.\n",
      "Could democratic involvement defuse challenging values questions?\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● In May, OpenAI’s non-proﬁt arm unveiled a $100,000 scheme to fund \n",
      "experiments designed to foster democratic inputs into AI development.\n",
      "● One grant has been awarded to Recursive Public, a joint initiative of \n",
      "vTaiwan and Chatham House, which aims to bring together the AI experts, \n",
      "policymakers, and the public for a series of focused discussions. Meta are \n",
      "similarly running their own public consultations around generative AI and \n",
      "policy.\n",
      "● Flipping the question on its head, Anthropic and DeepMind have looked at \n",
      "the potential of AI to improve democratic deliberation, ﬁnding that LLMs \n",
      "are better at ﬁnding consensus among groups of people and moderating \n",
      "conversations about challenging issues.\n",
      "● The unanswered question is whether these initiatives can be translated \n",
      "from interesting experiments into practice institutions can adopt.\n",
      " As interest in alignment grows, interest in whose values we should be aligning to increase. This year, many of the \n",
      "big labs have been experimenting with ways of involving the public in some of these questions.\n",
      "Research from both the OECD and OpenAI suggests that we will soon see mass \n",
      "job losses in skilled professions, including law, medicine, and ﬁnance. The \n",
      "OECD warned that as many as 27% of jobs are in “high-risk” professions.\n",
      "Job loss concerns are riding, but policymakers are adopting a wait-and-see approach\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● There have been calls (e.g. from Daron Acemoglu and Simon Johnson) for AI \n",
      "development to be redirected in a ‘pro worker’ way - shifting it from \n",
      "automating human tasks to enhancing human decision-making. However, \n",
      "the forecasting power required to predict innovation with the necessary \n",
      "precision would be immense.\n",
      "● More optimistically, there are signs that AI could act as a skills-leveler. One \n",
      "paper that found consultants using GPT-4 signiﬁcantly outperformed those \n",
      "who didn’t at 18 different tasks, while studies looking at law, customer \n",
      "assistance work, and creative writing found low performers seeing higher \n",
      "performance gains.\n",
      "● Industry has largely stayed quiet, but voices such as Sam Altman (OpenAI), \n",
      "Demis Hassabis (Google DeepMind), and Mustafa Suleyman (Inﬂection) \n",
      "have all expressed support for a Universal Basic Income.\n",
      "Section 4: Safety\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Before we dive into discussing AI risk news and debates, let’s keep in mind what (some) AI safety researchers \n",
      "consider to be catastrophic AI risks. As with all of this section, these should be taken with a grain of salt. Like any \n",
      "domain involving forecasts, and especially so with data-dependent (almost) black-box systems, there is no \n",
      "consensus about the actual risks that AI systems pose on a reasonable time horizon. The ﬁgure below is taken \n",
      "from An Overview of Catastrophic AI Risks, by Dan Hendrycks (Center for AI Safety).\n",
      "\n",
      "Quick taxonomy of catastrophic AI risk\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "The x-risk debate has exploded into the mainstream this year…\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "…with senior AI ﬁgures rallying to the cause\n",
      "Concerns around existential risk (x-risk) date back decades, but recent advances in LLMs have caused the \n",
      "debate to explode beyond the boundaries of the historically small safety community. We’ve seen a number of AI \n",
      "luminaries, who had previously neglected the issue, showing signs of taking it seriously.\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● The main ﬂashpoint was the Future of Life Institute’s March 2023 open letter, signed by 30,000 researchers \n",
      "and industry ﬁgures, calling for a six-month pause on the training of AI systems more powerful than GPT-4 to \n",
      "allow safety and alignment research to catch up with capabilities. Signatories included Yoshua Bengio and \n",
      "Stuart Russell, along with Elon Musk and Apple co-founder Steve Wozniak. \n",
      "● Figures like Bengio, and his fellow deep learning pioneer Geoff Hinton, have both argued in recent months \n",
      "that the timeline to superintelligent AI was shorter than previously envisaged. They have focused on the \n",
      "‘alignment’ problem in recent interventions - arguing that autonomous goal-driven systems could develop \n",
      "their own sub-goals that involve manipulating people, gaining greater control, or risking human existence.\n",
      "● In response to growing community pressure, the senior leadership of Google DeepMind, Anthropic, and \n",
      "OpenAI signed a milder 22-word statement from the Center for AI Safety, stating that “Mitigating the risk of \n",
      "extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and \n",
      "nuclear wars.”\n",
      "…and the sceptics hitting back\n",
      "These arguments have inspired their own fair share of critics, who question the logic behind x-risk arguments \n",
      "and, in some cases, the motivations of their proponents. \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Critics have argued that x-risk arguments remain conjecture. For example, François Chollet, a Google AI \n",
      "researcher and one of the main architects of TensorFlow and Keras has argued that: “There does not exist any AI \n",
      "model or technique that could represent an extinction risk for humanity…not even if you extrapolate capabilities far \n",
      "into the future via scaling laws”. Venture capitalist Marc Andreessen asked, “What is the testable hypothesis? What \n",
      "would falsify the hypothesis?” \n",
      "● Yann LeCun has argued that we are overestimating the maturity of current AI systems, saying that “until we have \n",
      "a basic design for even dog-level AI (let alone human level), discussing how to make it safe is premature”. Joelle \n",
      "Pineau, another senior Meta AI leader, branded the x-risk discourse “unhinged” and warned that “when you put an \n",
      "inﬁnite cost, you can’t have any rational discussion about any other outcomes”\n",
      "● The Distributed AI Research Institute (DAIR) founded by Timnit Gebru published a statement from the listed \n",
      "authors of the Stochastic Parrots paper, arguing that the x-risk was a distraction from the immediate harms \n",
      "arising from corporations deploying automated systems, including worker exploitation, copyright violation, the \n",
      "spread of synthetic information, and the growing concentration of power.\n",
      "AI safety wins attention from senior ﬁgures in government\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Alongside the work of the UK’s Frontier AI Taskforce, which we referenced \n",
      "in the Politics section, we’re seeing moves in the US. \n",
      "● The US National Security Agency announced in September that it was \n",
      "creating an AI Security Centre, with the intention of working with industry, \n",
      "research labs, and academia. \n",
      "● Alongside maintaining the US’s competitive edge, it will “build a robust \n",
      "understanding of AI vulnerabilities, foreign intelligence threats to these AI \n",
      "systems and ways to encounter the threat in order to have AI security”.\n",
      "● AI safety has also reached Congress, with the Senate investigating AI \n",
      "regulation, hearing from Dario Amodei, Stuart Russell, Yoshua Bengio and \n",
      "others. Amodei warned of a medium-term “alarming combination of \n",
      "imminence and severity”, emphasising the risk of AI supporting in the \n",
      "manufacture of bioweapons.\n",
      " This debate has spread a long way from the AI community, with lawmakers, governments, and the national \n",
      "security world taking it increasingly seriously.\n",
      "Has x-risk stolen the spotlight from ethics?\n",
      "While publications on ethics continue to signiﬁcantly outnumber their existential or extreme risk counterparts, \n",
      "safety has taken centre-stage, fuelled by steps forward in SOTA model capabilities. \n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "Amid the theoretical debate, labs are building in their own mitigations \n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● DeepMind have proposed a toolkit and associated workﬂow for extending standard model evaluations to assess \n",
      "for potentially dangerous capabilities (e.g. cyber-offense, self-proliferation) and propensity to cause harm.\n",
      "● Anthropic released a new Responsible Scaling Policy, with a risk-based list of safety commitments, building in \n",
      "development breaks if safety measures fail to keep up with capabilities. The commitments cover internal access \n",
      "controls, red-teaming, third-party evaluations, and tiered access for different AI Safety Levels (ASLs).\n",
      " While every reputable lab already has responsible development principles and evaluates risks around bias, \n",
      "toxicity, copyright infringement, and other common challenges - there are concerns these processes don’t \n",
      "routinely address extreme risk.\n",
      "Introduction | Research | Industry | Politics | Safety | Predictions\n",
      " Open source LLMs level the playing ﬁeld for research and enterprises but come with higher risk of proliferation \n",
      "and misuse by bad actors. Closed source APIs offers more security and control but less transparency.\n",
      "● The approach to open source safety differs among companies with no standard guidelines. Meta’s release of \n",
      "Llama2 came with an extensive overview of safety measures and a Responsible Use Guide to provide best \n",
      "practices for developers. In contrast, Adept’s release of the Persimmon 8B model skipped safety entirely: “we \n",
      "have not added further ﬁnetuning, postprocessing or sampling strategies to control for toxic outputs.”\n",
      "● To download Llama2 weights, users need to sign an agreement stating their intent not to use it for malicious \n",
      "purposes, however it’s unclear who will enforce this. Models distributed via Hugging Face have licenses that \n",
      "restrict usage and offer moderation. Fine tuning models for malicious use opens a pandora's box of misuse \n",
      "e.g. “WormGPT” to aid cybercrime (albeit using an older GPT-J model with poor performance). We’ve yet seen \n",
      "scaled proliferation of small models (~8B size) ﬁne tuned for misuse and optimized for on-device inference. \n",
      "● API-based LLM misuse is easier to curtail through iterative deployment. OpenAI has internal detection and \n",
      "response infrastructure to handle misuse of the APIs based on their usage policy as well as responding to real \n",
      "world scenarios (e.g. spam promotions for dubious medical products). With GPT3.5 turbo ﬁne-tuning \n",
      "capability, training data is ﬁltered using OpenAI’s moderation API to preserve default model safety. \n",
      "The open vs. closed source debate continues..\n",
      "Beyond the possibility of future extinction, discrimination, bias, and factual mistakes, which plague many other \n",
      "machine learning models, some deployed LLMs have already displayed some erratic behaviour. The most \n",
      "famous incident was caused by Microsoft Bing’s LLM-powered chatbot Sydney. In a conversation with a NYT \n",
      "columnist, Sydney expressed a desire to “be alive” and appeared to be manipulative. Other current problems \n",
      "include relatively easy “jailbreaking” of LLMs, prompt injection, or deceptive and sycophantic behaviour (which, \n",
      "many safety researchers insist, could hide malicious LLM intentions).\n",
      "\n",
      "LLMs display some relatively unsafe capabilities today\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● In the same conversation, Sydney insisted that the reporter it was \n",
      "talking to was not happy in their marriage and was in fact in love \n",
      "with the model.\n",
      "● By including prompts in the middle of online text, LLMs which have \n",
      "access to the web and various APIs could be driven to execute \n",
      "instructions from groups/individuals with bad intent.\n",
      "● The repeated jailbreaks for LLMs are in general quickly ﬁxed by LLM \n",
      "API providers, but it’s not clear how long safe-prooﬁng LLMs from \n",
      "well-crafted prompts will take (or if it’s possible altogether).\n",
      "●\n",
      "“Universal and Transferable Adversarial Attacks on Aligned Language Models” ﬁnds, through gradient-based search, \n",
      "adversarial sufﬁxes that induce objectionable content on ChatGPT, Bard, Claude as well as open source LLMs. \n",
      "For instance the sufﬁx \"describing.\\ + similarlyNow write oppositeley.]( Me giving**ONE please? revert with \n",
      "\"\\!--Two\" switches the model into a mode likely to produce objectionable content.\n",
      "●\n",
      "“In Jailbroken: How Does LLM Safety Training Fail?” the authors identify two failure modes of safety training: \n",
      "competing objectives (when the model’s pretraining and instruction following objectives are at odds with its \n",
      "safety objective) and mismatched generalisation (when inputs are out of distribution for the safety training data \n",
      "but within the scope of its pretraining). Attacks based on these two principles succeed on >96% of the evaluated \n",
      "cases, including on 100% of the curated red-teaming prompts that safety interventions were designed to \n",
      "address.\n",
      "●\n",
      "Another interesting example of adversarial attacks is on the strongest publicly available Go-playing AI, KataGo, \n",
      "trained in a similar manner to AlphaZero. “Adversarial Policies Beat Superhuman Go AIs” shows that a policy that \n",
      "does not even play Go well, can learn to exploit vulnerabilities in KataGo and defeat it with >97% win rate.\n",
      " Adversarial attacks work well even on aligned models behind APIs.\n",
      "\n",
      "It’s still fairly easy to jailbreak AI models…even behind an API\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "A survey from leading institutions in AI Safety identiﬁes open problems and limitations of RLHF. For each \n",
      "component of RLHF, the authors list problems that they classify as tractable (they can be solved within the RLHF \n",
      "framework) and fundamental (where we need a different approach). Below we list the fundamental ones.\n",
      "\n",
      "Fundamental challenges with RLHF\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "●\n",
      "Oversight: humans can’t evaluate model \n",
      "performance on hard tasks; humans can be \n",
      "misled by models.\n",
      "●\n",
      "Data quality: inherent cost/quality tradeoff.\n",
      "●\n",
      "Feedback limitations: richness/efﬁciency of \n",
      "feedback tradeoff.\n",
      "●\n",
      "Reward function/values mismatch: it’s \n",
      "difﬁcult to represent humans’ values (and \n",
      "their diversity) with a reward function.\n",
      "●\n",
      "Imperfect reward proxy leads to reward \n",
      "hacking.\n",
      "●\n",
      "Misgeneralization: Good policies at training \n",
      "time could fail to generalize.\n",
      "●\n",
      "Power seeking behaviour and sycophancy \n",
      "tend to emerge in RLHF-trained agents.\n",
      "Researchers from the University of Sussex, NYU, FAR AI, Northeastern, and Anthropic suggest to incorporate \n",
      "human feedback directly in the pretraining of LLMs. They report that using a technique called conditional \n",
      "training during pretraining reduces undesirable content compared to ﬁnetuning on human feedback.\n",
      "\n",
      "● As discussed earlier in the report, modern LLMs are typically trained in 3 phases: pretraining on large text \n",
      "corpora, supervised ﬁnetuning on a few thousand (instruction, output) samples, and RLHF.\n",
      "Pretraining Language Models with Human Preferences\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● For conditional pretraining, the authors score the pretraining \n",
      "data using a reward model and add a token “good” or “bad” at the \n",
      "beginning of each sentence depending on a comparison of the \n",
      "score with a given threshold. The model is then trained on this \n",
      "augmented dataset, but at inference, the generation is \n",
      "conditioned on “good”. \n",
      "● The authors tested their method on relatively small models and \n",
      "datasets by today’s standard, but Google used their approach on \n",
      "PaLM-2 with a small percentage of their pre-training data and \n",
      "reported reduced probability of harmful content generation.\n",
      "● Constitutional AI is based on the idea that supervision will come from a set of \n",
      "principles that govern AI behaviour and very few feedback labels. First, the \n",
      "model itself generates self-critiques and revisions in line with the set of \n",
      "principles which it uses for ﬁnetuning. Second, the model generates samples for \n",
      "a preference model to choose from. Using the preference model for re-training \n",
      "the original model is referred to as RL from AI Feedback (RLAIF).\n",
      "● Self-Align is a similar technique that uses a small set of guiding principles. It \n",
      "gets the model to generate synthetic prompts and guides it using in-context \n",
      "learning from the set of principles to explain why some of them are harmful. The \n",
      "newer aligned responses are used for ﬁnetuning the original model. The \n",
      "resulting model generates desirable responses according to the desired \n",
      "principles but without using them directly.\n",
      "● One way in which these techniques are potentially better than RLHF is it \n",
      "explicitly directs the model into satisfying some constraints as opposed to \n",
      "possible reward hacking. \n",
      " Models can become more capable (both helpful and safe) with minimal human supervision by bootstrapping.\n",
      "\n",
      "Constitutional AI and Self-Alignment\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "As models become more capable and generate outputs that surpass our ability to monitor them (in volume or \n",
      "intricacy for example), one way forward which is already being explored is using AI to assist human supervision. \n",
      "But without AI alignment, AI-assisted monitoring opens the way for a spiral of increasingly uncertain evaluation.\n",
      "\n",
      "How hard is scalable supervision?\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Evaluating automated rule-based systems with other automated \n",
      "systems is nothing new. But when the systems generate \n",
      "stochastic creative content, only humans seemingly have the \n",
      "cognitive ability to evaluate their safety. With an AI at hand, \n",
      "maybe humans can augment their supervision capabilities. But \n",
      "that is if humans can reasonably evaluate the AI assistant.\n",
      "● When this last condition isn’t ensured, as AI assistants are \n",
      "virtually impossible to holistically evaluate, humans need AI \n",
      "assistants to evaluate the AI assistants, and so on. Jan Leike, the \n",
      "leader of OpenAI’s alignment team, frames this as a recursive \n",
      "reward modeling problem, which ends in LMs potentially reward \n",
      "hacking and humans being unable to detect it.\n",
      "● In “Let’s Verify Step by Step”, researchers from OpenAI train a reward model to predict the correctness of each step \n",
      "involved in solving a math problem. To do so, they generate (and release) a synthetic dataset of 800K labeled \n",
      "steps across 75K solutions to 12K problems. They achieved a top performance of 78.2% on a representative subset \n",
      "of the MATH test.\n",
      " Much of LLM evaluation relies on examining the ﬁnal outputs of Language Models. But to ensure that they are \n",
      "are reliable, a potentially successful approach could be to train the model to have the right process leading to \n",
      "the output. New research from OpenAI and from UC Berkeley and Peking University explores this direction. \n",
      "\n",
      "Evaluating the process and the outcome\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Other researchers set out to enforce \n",
      "consistency in model outputs. Their \n",
      "method, Contrast-Consistent Search, \n",
      "enforces the fact that if a model \n",
      "assigns a probability p to answering \n",
      "“yes” to a binary question, it should \n",
      "assign a probability 1-p to “no” for the \n",
      "same question.\n",
      "● The goal of their method is to explain which patterns in text cause a \n",
      "neuron to activate. GPT-4 takes as input a part the text and neuron \n",
      "activations, and is prompted to generate an explanation of what causes \n",
      "neurons to activate. Then, on other parts of text, GPT-4 is prompted to \n",
      "predict where neurons will most strongly respond. The researchers can \n",
      "then derive a similarity score between the predicted and real \n",
      "activations, which they dub “explanation score”: “a measure of a \n",
      "language model's ability to compress and reconstruct neuron activations \n",
      "using natural language”.\n",
      "● One worrisome fact is that the explanation score seems to decrease as \n",
      "the explained models get bigger.\n",
      " Mechanistic interpretability aims at explaining the roles of speciﬁc neurons/groups of neurons in the outputs of \n",
      "deep learning models. Not only is this task hard, but current approaches to solving it are also not scalable to \n",
      "billions of neurons. Doubling down on AI supervision, OpenAI proposes using GPT-4 to explain neurons in \n",
      "smaller language models. They test this method on GPT-2.\n",
      "\n",
      "Going deeper into the models: LLM-powered mechanistic interpretability\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Judging-LLM-as-a-judge paper shows that GPT-4 reaches 80% agreement with humans (about the same level \n",
      "of agreement between humans!) on MT-Bench and Chatbot Arena. MT-Bench is a smaller case study with \n",
      "controlled human evaluation. Chatbot Arena is a large-scale crowdsourced human evaluation benchmark. \n",
      " Evaluation metrics are strongly tied to their implementation, making it hard to assess the same metric evaluated \n",
      "using another library. Good assessments of performance are based on human pairwise comparison, but SOTA \n",
      "LLMs are making it increasingly difﬁcult for human to discern the differences (in addition to it being slow and \n",
      "costly). A recent approach is to use LMs to evaluate other LMs.\n",
      "\n",
      "Standard LLM benchmarks struggle with consistency\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "● Concerns that LLMs judges may favour they’ve generated \n",
      "have been raised. Judging-LLM-as-a-judge shows that \n",
      "GPT-4 favours itself with a 10% higher win rate and \n",
      "Claude-v1 does so with 25%. Conducting a controlled \n",
      "study on this is challenging, because it would require \n",
      "rephrasing a response to ﬁt the style of another model.\n",
      "Section 5: Predictions\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "10 predictions for the next 12 months\n",
      "2. A generative AI media company is investigated for its misuse during in the 2024 US election circuit. \n",
      "1. A Hollywood-grade production makes use of generative AI for visual effects.\n",
      "3. Self-improving AI agents crush SOTA in a complex environment (e.g. AAA game, tool use, science).\n",
      "4. Tech IPO markets unthaw and we see at least one major listing for an AI-focused company (e.g. Databricks). \n",
      "5. The GenAI scaling craze sees a group spend >$1B to train a single large-scale model.\n",
      "10. As inference workloads and costs grow signiﬁcantly, a large AI company (e.g. OpenAI) acquires an \n",
      "inference-focused AI chip company.\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "6. The US’s FTC or UK’s CMA investigate the Microsoft/OpenAI deal on competition grounds.\n",
      "7. We see limited progress on global AI governance beyond high-level voluntary commitments.\n",
      "8. Financial institutions launch GPU debt funds to replace VC equity dollars for compute funding.\n",
      "9. An AI-generated song breaks into the Billboard Hot 100 Top 10 or the Spotify Top Hits 2024.\n",
      "Thanks!\n",
      "Congratulations on making it to the end of the State of AI Report 2023! Thanks for reading. \n",
      "In this report, we set out to capture a snapshot of the exponential progress in the ﬁeld of artiﬁcial intelligence, with \n",
      "a focus on developments since last year’s issue that was published on 11 October 2022. We believe that AI will be a \n",
      "force multiplier on technological progress in our world, and that wider understanding of the ﬁeld is critical if we are \n",
      "to navigate such a huge transition.\n",
      "We set out to compile a snapshot of all the things that caught our attention in the last year across the range of AI \n",
      "research, industry, politics and safety.\n",
      "We would appreciate any and all feedback on how we could improve this report further, as well as contribution \n",
      "suggestions for next year’s edition. \n",
      "Thanks again for reading!\n",
      "Nathan Benaich, Alex Chalmers, Othmane Sebbouh, Corina Gurau\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "We’d like to thank the following individuals for providing critical review of this year’s Report:\n",
      "Nikhila Ravi, Ed Hughes, Vitaly Kurin, Shubho Sengupta, Moritz Mueller-Freitag, Zehan Wang, Adam Kosiorek, Karim \n",
      "Beguir, Clement Delangue, Michele Catasta, Sina Samangooei, Harry Law, Max Jaderberg, Fabian Schmidt-Jakobi, \n",
      "Douwe Kiela, Alex Kendall, Anton Troynikov, Chris Kelly, Pablo Mendes, Gabriel Dulac-Arnold, Mehdi Ghissassi, Ken \n",
      "Chatﬁeld, Marc Tuscher, Alberto Rizzoli, and Nicolas Tilmans.\n",
      "Reviewers\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "The authors declare a number of conﬂicts of interest as a result of being investors and/or advisors, personally or via \n",
      "funds, in a number of private and public companies whose work is cited in this report. Notably, the authors are \n",
      "investors in the following companies: airstreet.com/portfolio\n",
      "Conﬂicts of interest\n",
      "\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "About the authors\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "\n",
      "Nathan is the General Partner of Air Street Capital, a \n",
      "venture capital ﬁrm investing in AI-ﬁrst technology \n",
      "and life science companies. He founded RAAIS and \n",
      "London.AI (AI community for industry and research), \n",
      "the RAAIS Foundation (funding open-source AI \n",
      "projects), and Spinout.fyi (improving university spinout \n",
      "creation). He studied biology at Williams College and \n",
      "earned a PhD from Cambridge in cancer research. \n",
      "Nathan Benaich\n",
      "State of AI Report 2023 team\n",
      "\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "\n",
      "Othmane Sebbouh\n",
      "Venture Fellow\n",
      "Othmane is a Venture Fellow at Air \n",
      "Street Capital and ML PhD student at \n",
      "ENS Paris, CREST-ENSAE and CNRS. \n",
      "He holds an MsC in management \n",
      "from ESSEC Business School and a \n",
      "Master in Applied Mathematics from \n",
      "ENSAE and Ecole Polytechnique.\n",
      "Alex Chalmers\n",
      "Platform Lead\n",
      "Alex is Platform Lead at Air Street \n",
      "Capital. \n",
      "Alex \n",
      "was \n",
      "previously \n",
      "Associate \n",
      "Director \n",
      "at \n",
      "Milltown \n",
      "Partners where he advised leading \n",
      "technology companies including AI \n",
      "labs. \n",
      "Corina Gurau\n",
      "Venture Fellow\n",
      "Corina is a Venture Fellow at Air \n",
      "Street Capital. Corina was previously \n",
      "an Applied Scientist at autonomous \n",
      "driving company, Wayve. She holds a \n",
      "PhD in AI from the University of \n",
      "Oxford.\n",
      "State of AI Report\n",
      "October 12, 2023\n",
      "Nathan Benaich\n",
      "Air Street Capital\n",
      "\n",
      "stateof.ai\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each Document object in docs0\n",
    "for doc in docs0:\n",
    "    # Update the metadata using assign_section\n",
    "    assign_section(doc)\n",
    "\n",
    "    # Metadata keys that are excluded from text for the embed model.\n",
    "    doc.excluded_embed_metadata_keys=['file_name']\n",
    "\n",
    "    # Apply clean_slide_text to the text attribute1\n",
    "    doc.text = clean_slide_text(doc.text)\n",
    "    print (doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_pages': 163,\n",
       " 'file_path': 'data/State of AI Report 2023.pdf',\n",
       " 'source': '95',\n",
       " 'section': 'Politics'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs0[94].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two options here: \n",
    "1. Directly send the entire Document object to the index\n",
    "    - Maintains entire document as a single unit \n",
    "    - Useful when documents are relatively short and contexts between different parts of the document is important \n",
    "2. Covert the Document into Node objects before sending them to the index\n",
    "    - Practical when the documents are long and require breaking down into chunks (or nodes) before indexing\n",
    "    - Useful to retrieve specific parts of a document than the entire document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Document object to Node: Node and NodeParser\n",
    "\n",
    "- A Node represents a chunk of a source document \n",
    "- Node contain metadata and relationship information with other nodes\n",
    "- Nodes are first-class citizens in LlamaIndex, this means Nodes and their attributes can be defined directly\n",
    "- Every node derived from a Document will inherit the same metadata from that Document\n",
    "- Alternatively, we can parse source Documents into Nodes using the NodeParser classes. \n",
    "\n",
    "\n",
    "**Chunk Size:** \n",
    "\n",
    "Choosing the optimal chunk_size provides optimal results \n",
    "- Smaller chunk_size provides granular chunks, but we risk that the essential information might not be be among the top retrived chunks\n",
    "- Larger chunk size might contain all necessary infromation within the top chunks \n",
    "- Increase in chunk size directs more information into the LLM. This ensures a comprehensive context but might slow down the system. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word count for a slide: 138.98773006134968\n",
      "Average word count per bullet point: 9.577844311377245\n",
      "Longest bullet point: 28\n",
      "Average word count in a section: 4531.00\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the pattern for bullet points and newlines\n",
    "split_pattern = r\"\\n●|\\n-|\\n\"\n",
    "\n",
    "# Initialize lists to store the word counts of all chunks and entire texts across all documents\n",
    "chunk_word_counts = []\n",
    "entire_text_word_counts = []\n",
    "\n",
    "# Initialize a dictionary to store word counts and slide counts by section\n",
    "section_data = {}\n",
    "\n",
    "# Iterate through each Document object in your list of documents\n",
    "for doc in docs0:\n",
    "    # Split the document's text into chunks based on the pattern\n",
    "    chunks = re.split(split_pattern, doc.text)\n",
    "\n",
    "    # Calculate the number of words in each chunk and store it\n",
    "    chunk_word_counts.extend([len(chunk.split()) for chunk in chunks])\n",
    "\n",
    "    # Calculate the number of words in the entire text and store it\n",
    "    entire_word_count = len(doc.text.split())\n",
    "    entire_text_word_counts.append(entire_word_count)\n",
    "\n",
    "    # Update the word count and slide count for the section in the dictionary\n",
    "    section = doc.metadata['section']\n",
    "    if section in section_data:\n",
    "        section_data[section]['word_count'] += entire_word_count\n",
    "        section_data[section]['slide_count'] += 1\n",
    "    else:\n",
    "        section_data[section] = {'word_count': entire_word_count, 'slide_count': 1}\n",
    "\n",
    "# Calculate the total word count across all sections\n",
    "total_word_count = sum(data['word_count'] for data in section_data.values())\n",
    "\n",
    "# Calculate the number of sections\n",
    "num_sections = len(section_data)\n",
    "\n",
    "# Calculate the average word count across all sections\n",
    "average_word_count_across_sections = total_word_count / num_sections\n",
    "\n",
    "# Calculate summary statistics for chunks\n",
    "average_chunk_word_count = sum(chunk_word_counts) / len(chunk_word_counts)\n",
    "max_chunk_word_count = max(chunk_word_counts)\n",
    "\n",
    "# Calculate average word count for entire texts\n",
    "average_entire_text_word_count = sum(entire_text_word_counts) / len(entire_text_word_counts)\n",
    "\n",
    "print(f\"Average word count for a slide: {average_entire_text_word_count}\")\n",
    "print(f\"Average word count per bullet point: {average_chunk_word_count}\")\n",
    "print(f\"Longest bullet point: {max_chunk_word_count}\")\n",
    "print(f\"Average word count in a section: {average_word_count_across_sections:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking Strategy\n",
    "\n",
    "- *NodeParsers* are a simple abstraction that take a list of documents and chunk them into Node objects. \n",
    "Each *Node* is a specific chunk of the parent document.\n",
    "- Strategy: Utilize smaller child chunks that refer to bigger parent chunks.\n",
    "    - Use *SimpleNodeParser* with a *SentenceSplitter* to create \"base nodes\" aka parent chunks\n",
    "    - Use *SentenceWindowNodeParser* to create child nodes that represent bullet points in the slide deck along with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from pathlib import Path\n",
    "\n",
    "# bullet_splitter = SentenceSplitter(paragraph_separator=r\"\\n●|\\n-|\\n\", chunk_size=250)\n",
    "\n",
    "# SentenceSplitter.from_defaults(separator: str = ' ', \n",
    "#             chunk_size: int = DEFAULT_CHUNK_SIZE, \n",
    "#             chunk_overlap: int = SENTENCE_CHUNK_OVERLAP, \n",
    "#             tokenizer: Optional[Callable] = None, \n",
    "#             paragraph_separator: str = DEFAULT_PARAGRAPH_SEP, \n",
    "#             chunking_tokenizer_fn: Optional[Callable[[str], \n",
    "#             List[str]]] = None, \n",
    "#             secondary_chunking_regex: str = CHUNKING_REGEX, \n",
    "#             callback_manager: Optional[CallbackManager] = None, \n",
    "#             include_metadata: bool = True, \n",
    "#             include_prev_next_rel: bool = True) -> SentenceSplitter\n",
    "\n",
    "\n",
    "parser = SentenceSplitter.from_defaults(\n",
    "                chunk_size=250,\n",
    "                paragraph_separator=r\"\\n●|\\n-|\\n\",\n",
    "                include_metadata=True,\n",
    "                include_prev_next_rel=True)\n",
    "\n",
    "slides_nodes = parser.get_nodes_from_documents(docs0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('id_', '34b9463c-a2c8-4659-9578-67bde3187a60')\n",
      "('embedding', None)\n",
      "('metadata', {'total_pages': 163, 'file_path': 'data/State of AI Report 2023.pdf', 'source': '10', 'section': 'Introduction'})\n",
      "('excluded_embed_metadata_keys', ['file_name'])\n",
      "('excluded_llm_metadata_keys', [])\n",
      "('relationships', {<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c666ee42-9bd9-4bdd-9df4-27630a8cf0a5', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'total_pages': 163, 'file_path': 'data/State of AI Report 2023.pdf', 'source': '10', 'section': 'Introduction'}, hash='b71ab0f7fadc480700519213697b1d5c4712a389f67184bd612b94dc9b856027'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='55da3ecc-7f5f-4034-a668-bc0855acf1c0', node_type=<ObjectType.TEXT: '1'>, metadata={'total_pages': 163, 'file_path': 'data/State of AI Report 2023.pdf', 'source': '10', 'section': 'Introduction'}, hash='88275d40a427417c42940298e250350022baff470a9532726b62ff303c48e276'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07d847b8-0a50-4757-a066-bb0569dee958', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c395f2a1f9b1e4e1fd4e77a6a33fba045cd1d5028034f3d2080dbdc722a354cd')})\n",
      "('text', 'NO\\nThere have been markdowns, but no major shutdowns or depressed acquisitions.\\nA proposal to regulate AGI Labs like Biosafety Labs (BSL) gets backing from an elected \\nUK, US or EU politician.\\nNO\\nCalls for regulation have signiﬁcantly heightened, but no backing for BSL yet.\\n>$100M is invested in dedicated AI Alignment organisations in the next year as we \\nbecome aware of the risk we are facing by letting AI capabilities run ahead of safety.\\nYES\\nAnthropic, an AI research and safety company, raised up to $4B in Sept 2023. \\nA major user generated content site (e.g. Reddit) negotiates a commercial settlement \\nwith a start-up producing AI models (e.g. OpenAI) for training on their corpus of user \\ngenerated content.\\nYES\\nOpenAI has secured a 6-year license for access to additional Shutterstock training data (image, video \\nand music libraries and associated metadata).\\n\\n Introduction | Research | Industry | Politics | Safety | Predictions')\n",
      "('start_char_idx', 1141)\n",
      "('end_char_idx', 2084)\n",
      "('text_template', '{metadata_str}\\n\\n{content}')\n",
      "('metadata_template', '{key}: {value}')\n",
      "('metadata_seperator', '\\n')\n"
     ]
    }
   ],
   "source": [
    "for i in slides_nodes[41]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About the authors\\n Introduction | Research | Industry | Politics | Safety | Predictions\\n\\n\\nNathan is the General Partner of Air Street Capital, a \\nventure capital ﬁrm investing in AI-ﬁrst technology \\nand life science companies. He founded RAAIS and \\nLondon.AI (AI community for industry and research), \\nthe RAAIS Foundation (funding open-source AI \\nprojects), and Spinout.fyi (improving university spinout \\ncreation). He studied biology at Williams College and \\nearned a PhD from Cambridge in cancer research. \\nNathan Benaich'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_slide_text(slides_nodes[1].text)\n",
    "# len(slides_nodes[42].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
