{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG using Llamaindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup environment \n",
    "\n",
    "!python3 -m venv rag-pipeline -- quiet\n",
    "!source rag/bin/activate --quiet\n",
    "\n",
    "##### Install dependencies\n",
    "\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "docs0 = loader.load_data(file_path=Path(\"data/State of AI Report 2023.pdf\"), metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " docs is a <class 'list'>, of length 163, where each element is a <class 'llama_index.core.schema.Document'> object\n"
     ]
    }
   ],
   "source": [
    "print(f\" docs is a {type(docs0)}, of length {len(docs0)}, where each element is a {type(docs0[0])} object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_', 'embedding', 'metadata', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'relationships', 'text', 'start_char_idx', 'end_char_idx', 'text_template', 'metadata_template', 'metadata_seperator']\n",
      "    In Oct 2022, Shutterstock - a leading stock multimedia provider - announced it will work with OpenAI to bring \n",
      "DALL·E-powered content onto the platform. Then in July 2023, the two companies signed a 6-year content \n",
      "licensing agreement that would give OpenAI access to Shutterstock's image, video and music libraries and \n",
      "associated metadata for model training. Furthermore, Shutterstock will offer its customers indemniﬁcation for AI \n",
      "image creation. The company also entered into a content license with Meta for GenAI. This pro-GenAI stance is in \n",
      "stark contrast to Shutterstock’s competitor, Getty Images, which is profoundly against GenAI as evidenced by its \n",
      "ongoing lawsuit against Stability AI for copyright infringement ﬁled in Feb 2023. \n",
      "stateof.ai 2023\n",
      "#stateofai | 95\n",
      " Introduction | Research | Industry | Politics | Safety | Predictions\n",
      "2022 Prediction: A major user generated content site negotiates a commercial \n",
      "settlement with a start-up producing AI models (e.g. OpenAI) for training on their corpus\n",
      "vs.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(id_='d0ac5c48-c85e-41d6-b09e-2adf6e7af9a5', embedding=None, metadata={'total_pages': 163, 'file_path': 'data/State of AI Report 2023.pdf', 'source': '95'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"    In Oct 2022, Shutterstock - a leading stock multimedia provider - announced it will work with OpenAI to bring \\nDALL·E-powered content onto the platform. Then in July 2023, the two companies signed a 6-year content \\nlicensing agreement that would give OpenAI access to Shutterstock's image, video and music libraries and \\nassociated metadata for model training. Furthermore, Shutterstock will offer its customers indemniﬁcation for AI \\nimage creation. The company also entered into a content license with Meta for GenAI. This pro-GenAI stance is in \\nstark contrast to Shutterstock’s competitor, Getty Images, which is profoundly against GenAI as evidenced by its \\nongoing lawsuit against Stability AI for copyright infringement ﬁled in Feb 2023. \\nstateof.ai 2023\\n#stateofai | 95\\n Introduction | Research | Industry | Politics | Safety | Predictions\\n2022 Prediction: A major user generated content site negotiates a commercial \\nsettlement with a start-up producing AI models (e.g. OpenAI) for training on their corpus\\nvs.\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ([k for k, v in docs0[94]])\n",
    "\n",
    "print (docs0[94].get_content())\n",
    "\n",
    "[v for k,v in docs0[94] if k=='metadata']\n",
    "\n",
    "docs0[94]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text and add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_slide_text(text:str) -> str: \n",
    "    \"\"\"\n",
    "    Cleans the provided slide by removing specific patterns and extra whitespace. \n",
    "    \n",
    "    Parameters:\n",
    "\n",
    "    Returns: \n",
    "    \"\"\"\n",
    "    # Remove the footer text\n",
    "    text = text.replace(\"stateof.ai 2023\", \"\")\n",
    "\n",
    "    # Remove the header text\n",
    "    text = text.replace(\"Introduction  | Research  | Industry  | Politics  | Safety  | Predictions\", \"\")\n",
    "\n",
    "    # Remove the pattern \"#stateofai | n\"\n",
    "    text = re.sub(r\"#stateofai(\\s*\\|\\s*\\d+)?\", \"\", text)\n",
    "\n",
    "    # Replace multiple consecutive spaces with a single space\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "\n",
    "    # Remove any leading or trailing whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_section(document):\n",
    "    \"\"\"\n",
    "    Assigns a section to the document based on its page number.\n",
    "\n",
    "    The function updates the 'metadata' attribute of the document with a key 'section'\n",
    "    that has a value corresponding to the section the page number falls into.\n",
    "\n",
    "    Sections:\n",
    "    - Page 1 through 10: Introduction\n",
    "    - Page 11 through 68: Research\n",
    "    - Page 69 through 120: Politics\n",
    "    - Page 121 through 137: Safety\n",
    "    - Pages 138 and beyond: Predictions\n",
    "\n",
    "    Args:\n",
    "    - document (Document): The Document object to be updated.\n",
    "\n",
    "    Returns:\n",
    "    None. The function updates the Document object in-place.\n",
    "    \"\"\"\n",
    "\n",
    "    page_number = int(document.metadata['source'])\n",
    "\n",
    "    if 1 <= page_number <= 10:\n",
    "        document.metadata['section'] = 'Introduction'\n",
    "    elif 11 <= page_number <= 68:\n",
    "        document.metadata['section'] = 'Research'\n",
    "    elif 69 <= page_number <= 120:\n",
    "        document.metadata['section'] = 'Politics'\n",
    "    elif 121 <= page_number <= 137:\n",
    "        document.metadata['section'] = 'Safety'\n",
    "    else:\n",
    "        document.metadata['section'] = 'Predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each Document object in docs0\n",
    "for doc in docs0:\n",
    "    # Update the metadata using assign_section\n",
    "    assign_section(doc)\n",
    "\n",
    "    # Metadata keys that are excluded from text for the embed model.\n",
    "    doc.excluded_embed_metadata_keys=['file_name']\n",
    "\n",
    "    # Apply clean_slide_text to the text attribute1\n",
    "    doc.text = clean_slide_text(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_pages': 163,\n",
       " 'file_path': 'data/State of AI Report 2023.pdf',\n",
       " 'source': '95',\n",
       " 'section': 'Politics'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs0[94].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two options here: \n",
    "1. Directly send the entire Document object to the index\n",
    "    - Maintains entire document as a single unit \n",
    "    - Useful when documents are relatively short and contexts between different parts of the document is important \n",
    "2. Covert the Document into Node objects before sending them to the index\n",
    "    - Practical when the documents are long and require breaking down into chunks (or nodes) before indexing\n",
    "    - Useful to retrieve specific parts of a document than the entire document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Document object to Node\n",
    "\n",
    "- A Node represents a chunk of a source document \n",
    "- Node contain metadata and relationship information with other nodes\n",
    "- Nodes are first-class citizens in LlamaIndex, this means Nodes and their attributes can be defined directly\n",
    "- Every node derived from a Document will inherit the same metadata from that Document \n",
    "\n",
    "**Chunk Size:** \n",
    "\n",
    "Choosing the optimal chunk_size provides optimal results \n",
    "- Smaller chunk_size provides granular chunks, but we risk that the essential information might not be be among the top retrived chunks\n",
    "- Larger chunk size might contain all necessary infromation within the top chunks \n",
    "- Increase in chunk size directs more information into the LLM. This ensures a comprehensive context but might slow down the system. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word count for a slide: 138.98773006134968\n",
      "Average word count per bullet point: 9.577844311377245\n",
      "Longest bullet point: 28\n",
      "Average word count in a section: 4531.00\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the pattern for bullet points and newlines\n",
    "split_pattern = r\"\\n●|\\n-|\\n\"\n",
    "\n",
    "# Initialize lists to store the word counts of all chunks and entire texts across all documents\n",
    "chunk_word_counts = []\n",
    "entire_text_word_counts = []\n",
    "\n",
    "# Initialize a dictionary to store word counts and slide counts by section\n",
    "section_data = {}\n",
    "\n",
    "# Iterate through each Document object in your list of documents\n",
    "for doc in docs0:\n",
    "    # Split the document's text into chunks based on the pattern\n",
    "    chunks = re.split(split_pattern, doc.text)\n",
    "\n",
    "    # Calculate the number of words in each chunk and store it\n",
    "    chunk_word_counts.extend([len(chunk.split()) for chunk in chunks])\n",
    "\n",
    "    # Calculate the number of words in the entire text and store it\n",
    "    entire_word_count = len(doc.text.split())\n",
    "    entire_text_word_counts.append(entire_word_count)\n",
    "\n",
    "    # Update the word count and slide count for the section in the dictionary\n",
    "    section = doc.metadata['section']\n",
    "    if section in section_data:\n",
    "        section_data[section]['word_count'] += entire_word_count\n",
    "        section_data[section]['slide_count'] += 1\n",
    "    else:\n",
    "        section_data[section] = {'word_count': entire_word_count, 'slide_count': 1}\n",
    "\n",
    "# Calculate the total word count across all sections\n",
    "total_word_count = sum(data['word_count'] for data in section_data.values())\n",
    "\n",
    "# Calculate the number of sections\n",
    "num_sections = len(section_data)\n",
    "\n",
    "# Calculate the average word count across all sections\n",
    "average_word_count_across_sections = total_word_count / num_sections\n",
    "\n",
    "# Calculate summary statistics for chunks\n",
    "average_chunk_word_count = sum(chunk_word_counts) / len(chunk_word_counts)\n",
    "max_chunk_word_count = max(chunk_word_counts)\n",
    "\n",
    "# Calculate average word count for entire texts\n",
    "average_entire_text_word_count = sum(entire_text_word_counts) / len(entire_text_word_counts)\n",
    "\n",
    "print(f\"Average word count for a slide: {average_entire_text_word_count}\")\n",
    "print(f\"Average word count per bullet point: {average_chunk_word_count}\")\n",
    "print(f\"Longest bullet point: {max_chunk_word_count}\")\n",
    "print(f\"Average word count in a section: {average_word_count_across_sections:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
